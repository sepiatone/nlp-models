{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-rnn_ner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AU3aenm0Zota",
        "DzQs9WJngfsp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDEsdD3Wsda",
        "colab_type": "text"
      },
      "source": [
        "#### **RNN for Named Entity Recognition**\n",
        "\n",
        "The NLP task [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition) (NER) is to classify named entity's within a corpus into predefined categories.\n",
        "\n",
        "We explore the use of a recurrent architecture to perform NER. The dataset used is the MIT-Restaurants dataset. The tagging of the dataset is in the [IOB2](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) format.\n",
        "\n",
        "Note: Framework based off https://github.com/lingo-mit/6864-hw2/blob/master/6864_hw2.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3aenm0Zota",
        "colab_type": "text"
      },
      "source": [
        "#### **Setup**\n",
        "\n",
        "Import required libraris and then read in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRcN9c6leOWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "9c08e425-9405-45c7-82cb-93b54d8fd7e4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import util\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\" # use a gpu!\n",
        "\n",
        "\n",
        "train_data = util.read_file_txt(\"../data/mit_restaurants-train.dat\", type = \"word\")\n",
        "train_tags = util.read_file_txt(\"../data/mit_restaurants-train.tag\", type = \"word\")\n",
        "\n",
        "test_data = util.read_file_txt(\"../data/mit_restaurants-test.dat\", type = \"word\")\n",
        "test_tags = util.read_file_txt(\"../data/mit_restaurants-test.tag\", type = \"word\")\n",
        "\n",
        "print('number of training samples:', len(train_data))\n",
        "print('number of testing samples:',  len(test_data))\n",
        "# print('average sentence length in training data', (np.mean([len(sent) for sent in train_data])))\n",
        "print()\n",
        "\n",
        "print('the first few sentences are:', train_data[0:3])\n",
        "print('and their cp\\'ding named entity sequences are: ', str(train_tags[0:3]))\n",
        "print()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training samples: 7660\n",
            "number of testing samples: 1521\n",
            "\n",
            "the first few sentences are: [['2', 'start', 'restaurants', 'with', 'inside', 'dining'], ['34'], ['5', 'star', 'resturants', 'in', 'my', 'town']]\n",
            "and their cp'ding named entity sequences are:  [['B-Rating', 'I-Rating', 'O', 'O', 'B-Amenity', 'I-Amenity'], ['O'], ['B-Rating', 'I-Rating', 'O', 'B-Location', 'I-Location', 'I-Location']]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzQs9WJngfsp",
        "colab_type": "text"
      },
      "source": [
        "#### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44uSZVEXg48r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "e3bb1718-a42e-4f34-d8c7-27f678717eae"
      },
      "source": [
        "# helper functions and more data preprocessing before we move on to implementing our models.\n",
        "\n",
        "# from train data, collect all unique word types as a set and add 'UNK' to it (unseen words in test data will be turned into 'UNK')\n",
        "vocab_set = list(set([word for sent in train_data for word in sent])) + ['UNK']\n",
        "num_vocabs = len(vocab_set)\n",
        "print(\"number of word types (including 'UNK'):\", num_vocabs)\n",
        "print(\"the first couple and last couple of words in the vocabulary set:\", vocab_set[0:2] +  vocab_set[-2:])\n",
        "\n",
        "vocab2id = {v : i for i, v in enumerate(vocab_set)}\n",
        "\n",
        "#  collect all tag (class) types and assign an unique id to each of them. (here there won't be a unseen tag type in test data)\n",
        "tag_set = list(set([tag for tag_seq in train_tags for tag in tag_seq]))\n",
        "num_tags = len(tag_set)\n",
        "print(\"number of tag types:\", num_tags)\n",
        "print()\n",
        "\n",
        "# assign each tag type a unique id, also create the inverse dict of tag2id (required during evaluation)\n",
        "tag2id = {t : i for i, t in enumerate(tag_set)} \n",
        "id2tag = {i : t for t, i in tag2id.items()}\n",
        "\n",
        "# apply one-hot encoding to data.\n",
        "train_data_oh_list = [util.one_hot_encoding(sent, vocab2id, vocab_set) for sent in train_data]\n",
        "# print(\"oh data[0] - len:\", len(train_data_oh_list[0]), \"shape:\", train_data_oh_list[0].shape)\n",
        "\n",
        "# transform tag names into ids\n",
        "train_tags_id_list = [util.encoding_idx(tag_seq, tag2id) for tag_seq in train_tags]\n",
        "# print(\"list len, tag data:\", len(train_tags_id_list))\n",
        "\n",
        "# train_data_oh_list should now be a list of 2d-tensors, each has shape (sent_len, num_vocabs)\n",
        "# Note that to utilize the `shape` attribute, each element in the list should already be a torch tensor.\n",
        "print(\"first sentence has shape: %s\" % str(train_data_oh_list[0].shape))\n",
        "print(\"fifth sentence has shape: %s\" % str(train_data_oh_list[4].shape))\n",
        "\n",
        "# train_tags_id_list is a list of 1d-tensors, each that has shape (sent_len,)\n",
        "print(\"first tag sequence has shape: %s\" % train_tags_id_list[0].shape)\n",
        "print(\"fifth tag sequence has shape: %s\" % train_tags_id_list[4].shape)\n",
        "print()\n",
        "\n",
        "\n",
        "# Apply same conversion to test dataset.\n",
        "test_data_oh_list = [util.one_hot_encoding(sent, vocab2id, vocab_set) for sent in test_data]\n",
        "test_tags_id_list = [util.encoding_idx(tag_seq, tag2id) for tag_seq in test_tags]\n",
        "# print(\"list len, oh test:\", len(test_data_oh_list))\n",
        "# print(\"list len, tag test:\", len(test_tags_id_list))\n",
        "# print(\"first sentence has shape: %s\" % str(test_data_oh_list[0].shape))\n",
        "# print(\"fifth sentence has shape: %s\" % str(test_data_oh_list[4].shape))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of word types (including 'UNK'): 3805\n",
            "the first couple and last couple of words in the vocabulary set: ['creme', 'inernational', 'meats', 'UNK']\n",
            "number of tag types: 17\n",
            "\n",
            "first sentence has shape: torch.Size([6, 3805])\n",
            "fifth sentence has shape: torch.Size([12, 3805])\n",
            "first tag sequence has shape: 6\n",
            "fifth tag sequence has shape: 12\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7gCDSGGdfeZ",
        "colab_type": "text"
      },
      "source": [
        "#### **RNN**\n",
        "\n",
        "We implement a vanilla RNN from scratch, then train it and evaluate its performance on the NER task.\n",
        "\n",
        "The RNN is implemented using [Elman](https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks) units and the $tanh$ non-linear activation function. The input size was set to the vocbulary size of the dataset, the size of the hidden state was set to $128$ and the output size was set to the number of tags in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m37BjwIIef15",
        "colab_type": "text"
      },
      "source": [
        "##### **RNN architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_t2jPVDd3bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN_NER(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.hidden = nn.Linear(self.input_size + self.hidden_size, self.hidden_size)\n",
        "    self.output = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    \"\"\"\n",
        "    The `forward` function should just perform one step of update and output logits before softmax.\n",
        "    `x` is a 2d-tensor of shape (1, input_size); `hidden` is another 2d-tensor of shape (1, hidden_size), representing the hidden state of\n",
        "    the previous time step.\n",
        "    \"\"\"\n",
        "\n",
        "    combined = torch.cat( (x, hidden), dim = 1)\n",
        "    hidden = torch.tanh(self.hidden(combined))\n",
        "    output = self.output(hidden)\n",
        "\n",
        "    return output, hidden\n",
        "    \n",
        "\n",
        "  def init_state(self):\n",
        "    \"\"\" Use to initialize hidden state everytime before running a sentence. \"\"\"\n",
        "    return torch.zeros(1, self.hidden_size).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxQfXsM0dz4m",
        "colab_type": "text"
      },
      "source": [
        "##### **Training**\n",
        "\n",
        "The function $train\\_one\\_sample$, takes a (sentence tensor, tag tensor) pair as input and does one step of the gradient update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPrT97TNWkHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "a7b2f074-391e-442a-e36c-b318cb740fb2"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "rnn_hidden_size = 128\n",
        "grad_clip = 1\n",
        "\n",
        "\n",
        "model = RNN_NER(input_size = num_vocabs, hidden_size = rnn_hidden_size, output_size = num_tags).to(device)\n",
        "print(\"The model has {} parameters\".format(sum(p.numel() for p in model.parameters())))\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Run through a sentence, generate output, compute loss, and perform one gradient update\n",
        "Sentence and tag are represented as a 2d-tensor `sent_tensor` and a 1d-tensor `tag_tensor`, respectively.\n",
        "\"\"\"\n",
        "def train_one_sample(model, sent_tensor, tag_tensor):\n",
        "  hidden = model.init_state() # initialize hidden state\n",
        "  loss = torch.zeros( 1, dtype = torch.float).to(device)\n",
        "\n",
        "  outputs = torch.zeros( (1, num_tags)).to(device)\n",
        "\n",
        "  for idx in range(sent_tensor.shape[0]):\n",
        "    outputs, hidden = model(sent_tensor[idx].reshape(1, sent_tensor.shape[1]), hidden)\n",
        "    loss = loss + criterion(outputs, torch.LongTensor([tag_tensor[idx]]).to(device))\n",
        "      \n",
        "  loss = loss / len(tag_tensor)   # average the loss over all tags in the sentance\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "  optimizer.step()\n",
        "\n",
        "  return outputs, loss.item()\n",
        "\n",
        "\n",
        "# main training loop for the rnn\n",
        "num_epochs = 5\n",
        "iter_count = 0\n",
        "print_every = 2500\n",
        "plot_every = 50\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "b_calc_grad_norm = True # set to true if we want to analyze how the gradient changes over training\n",
        "\n",
        "if b_calc_grad_norm:\n",
        "  current_grad_norm = 0\n",
        "  all_grad_norms = []\n",
        "  tmp = []\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "model.train()\n",
        " \n",
        "for idx_epoch in range(num_epochs):\n",
        "  for sent_tensor, tag_tensor in zip(train_data_oh_list, train_tags_id_list):\n",
        "    sent_tensor = sent_tensor.to(device)\n",
        "    tag_tensor = tag_tensor.to(device)\n",
        "\n",
        "    output, loss = train_one_sample(model, sent_tensor, tag_tensor)\n",
        "    current_loss += loss\n",
        "    \n",
        "    if b_calc_grad_norm:\n",
        "      grad = torch.zeros(1, dtype = torch.float).to(device)\n",
        "      \n",
        "      for param in model.parameters():\n",
        "        grad = torch.cat( (grad, torch.reshape(param.grad, (-1, ))))\n",
        "      \n",
        "      current_grad_norm += grad.to(\"cpu\") # torch.norm(grad.to(\"cpu\"), 2)\n",
        "\n",
        "\n",
        "    if iter_count % print_every == 0:      \n",
        "      print(\"epoch: {}, iteration: {}, time: {}, loss: {:0.4f}\".format(idx_epoch, iter_count, util.time_since(start), loss))\n",
        "\n",
        "\n",
        "    # add current loss avg to list of losses\n",
        "    if iter_count % plot_every == 0 and iter_count > 0:\n",
        "      all_losses.append(current_loss / plot_every)\n",
        "      current_loss = 0\n",
        "      \n",
        "      if b_calc_grad_norm: \n",
        "        all_grad_norms.append(torch.norm(current_grad_norm) / plot_every)\n",
        "        current_grad_norm = 0\n",
        "\n",
        "\n",
        "    iter_count += 1"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 505745 parameters\n",
            "epoch: 0, iteration: 0, time: 0m 0s, loss: 2.8372\n",
            "epoch: 0, iteration: 2500, time: 0m 17s, loss: 1.5156\n",
            "epoch: 0, iteration: 5000, time: 0m 35s, loss: 0.1079\n",
            "epoch: 0, iteration: 7500, time: 0m 52s, loss: 0.7855\n",
            "epoch: 1, iteration: 10000, time: 1m 10s, loss: 0.2964\n",
            "epoch: 1, iteration: 12500, time: 1m 28s, loss: 0.3061\n",
            "epoch: 1, iteration: 15000, time: 1m 45s, loss: 1.9776\n",
            "epoch: 2, iteration: 17500, time: 2m 2s, loss: 0.4908\n",
            "epoch: 2, iteration: 20000, time: 2m 21s, loss: 1.1489\n",
            "epoch: 2, iteration: 22500, time: 2m 38s, loss: 0.7953\n",
            "epoch: 3, iteration: 25000, time: 2m 55s, loss: 0.0201\n",
            "epoch: 3, iteration: 27500, time: 3m 14s, loss: 0.7401\n",
            "epoch: 3, iteration: 30000, time: 3m 31s, loss: 0.0158\n",
            "epoch: 4, iteration: 32500, time: 3m 48s, loss: 0.0197\n",
            "epoch: 4, iteration: 35000, time: 4m 7s, loss: 0.9547\n",
            "epoch: 4, iteration: 37500, time: 4m 24s, loss: 0.5049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wicccX-eNZu",
        "colab_type": "text"
      },
      "source": [
        "##### **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwsFjcYBmWL_",
        "colab_type": "text"
      },
      "source": [
        "We plot the learning curve. We also evaluate the model on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eYuprdb3d1i",
        "colab_type": "text"
      },
      "source": [
        "###### **Learning Curve**\n",
        "\n",
        "We plot the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KPXOHLheN7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5570a4e4-1271-4de4-e3b1-5f96e915f56b"
      },
      "source": [
        "# plot the learning curve. The x-axis is the training iterations and the y-axis is the training loss. The loss should be going down.\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "x_axis_pts = np.array([idx for idx, _ in enumerate(all_losses)])\n",
        "\n",
        "if b_calc_grad_norm:\n",
        "  fig, (ax_1, ax_2) = plt.subplots(1, 2)\n",
        "  fig.subplots_adjust(wspace = 0.50)\n",
        "  \n",
        "  ax_1.plot(x_axis_pts, all_losses)\n",
        "  ax_1.set_xlabel(\"iteration\")\n",
        "  ax_1.set_ylabel(\"loss\")\n",
        "  ax_1.set_title(\"learning curve\");\n",
        "\n",
        "  ax_2.plot(x_axis_pts, all_grad_norms)\n",
        "  ax_2.set_xlabel(\"iteration\")\n",
        "  ax_2.set_ylabel(\"norm of the gradient\")\n",
        "  ax_2.set_title(\"gradient norm\");\n",
        "\n",
        "else:\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(x_axis_pts, all_losses)\n",
        "  ax.set_xlabel(\"iteration\")\n",
        "  ax.set_ylabel(\"loss\")\n",
        "  ax.set_title(\"learning curve\");\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI7jOLgycBzHcYD/D9Aif+JT7P8PAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P90yPixR3ojS",
        "colab_type": "text"
      },
      "source": [
        "###### **Inference**\n",
        "\n",
        "We use the trained model to run inference on the test dataset and compute the [precision, recall](https://en.wikipedia.org/wiki/Precision_and_recall) and [f1 score](https://en.wikipedia.org/wiki/F1_score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVj-JXcOmkBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d434b7bd-46bf-4903-83bb-3b9d702a19aa"
      },
      "source": [
        "# Make prediction for one sentence.\n",
        "def predict(model, sent_tensor):\n",
        "  hidden = model.init_state()\n",
        "\n",
        "  predicted_tag_id = []\n",
        "\n",
        "  for idx in range(sent_tensor.shape[0]):\n",
        "    outputs, hidden = model(sent_tensor[idx].reshape(1, sent_tensor.shape[1]), hidden)\n",
        "    predicted_tag_id.append(np.argmax(outputs.detach().cpu().numpy()))\n",
        "\n",
        "  return predicted_tag_id\n",
        " \n",
        " \n",
        "model.eval()\n",
        "predicted_tags = []\n",
        " \n",
        "for sent_tensor in test_data_oh_list:\n",
        "    sent_tensor = sent_tensor.to(device)\n",
        "    predicted_tag_id = predict(model, sent_tensor)\n",
        "    predicted_tags.append([id2tag[idx] for idx in predicted_tag_id])\n",
        "  \n",
        "   \n",
        "# precision, recall, and f1 score\n",
        "\n",
        "# Example: true_tag_list/predicted_tag_list:\n",
        "#   [[‘O’, ‘O’, ‘I’, ‘N’, ...]\n",
        "#    [‘I’, ‘I’, ‘O’, ‘N’, ...]],\n",
        "precision, recall, f1_score = util.evaluate_result(test_tags, predicted_tags)\n",
        "print(\"precision: {:0.4f}, recall: {:0.4f}, f1 score: {:0.4f}\".format(precision, recall, f1_score))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.7574, recall: 0.7609, f1 score: 0.7524\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}