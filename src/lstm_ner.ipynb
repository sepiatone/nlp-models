{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_ner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AU3aenm0Zota",
        "DzQs9WJngfsp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDEsdD3Wsda",
        "colab_type": "text"
      },
      "source": [
        "#### **Named Entity Recognition using LSTM**\n",
        "\n",
        "The NLP task [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition) (NER) is to classify named entity's within a corpus into predefined categories.\n",
        "\n",
        "We explore the use of a [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) architecture to perform NER. The dataset used is the MIT-Restaurants dataset. The tagging of the dataset is in the [IOB2](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) format.\n",
        "\n",
        "Note: Framework based off https://github.com/lingo-mit/6864-hw2/blob/master/6864_hw2.ipynb\n",
        "\n",
        "Note: For a gentler introduction to the LSTM architecture see [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3aenm0Zota",
        "colab_type": "text"
      },
      "source": [
        "#### **Setup**\n",
        "\n",
        "Import and read in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRcN9c6leOWo",
        "colab_type": "code",
        "outputId": "9e94b4c3-7000-4bb9-fb44-7008a32891d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import util\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\" # use a gpu!\n",
        "\n",
        "\n",
        "train_data = util.read_file_txt(\"../data/mit_restaurants-train.dat\", type = \"word\")\n",
        "train_tags = util.read_file_txt(\"../data/mit_restaurants-train.tag\", type = \"word\")\n",
        "\n",
        "test_data = util.read_file_txt(\"../data/mit_restaurants-test.dat\", type = \"word\")\n",
        "test_tags = util.read_file_txt(\"../data/mit_restaurants-test.tag\", type = \"word\")\n",
        "\n",
        "print('number of training samples:', len(train_data))\n",
        "print('number of testing samples:',  len(test_data))\n",
        "# print('average sentence length in training data', (np.mean([len(sent) for sent in train_data])))\n",
        "print()\n",
        "\n",
        "print('the first few sentences are:', train_data[0:3])\n",
        "print('and their cp\\'ding named entity sequences are: ', str(train_tags[0:3]))\n",
        "print()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training samples: 7660\n",
            "number of testing samples: 1521\n",
            "\n",
            "the first few sentences are: [['2', 'start', 'restaurants', 'with', 'inside', 'dining'], ['34'], ['5', 'star', 'resturants', 'in', 'my', 'town']]\n",
            "and their cp'ding named entity sequences are:  [['B-Rating', 'I-Rating', 'O', 'O', 'B-Amenity', 'I-Amenity'], ['O'], ['B-Rating', 'I-Rating', 'O', 'B-Location', 'I-Location', 'I-Location']]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzQs9WJngfsp",
        "colab_type": "text"
      },
      "source": [
        "#### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44uSZVEXg48r",
        "colab_type": "code",
        "outputId": "9463476c-b8e7-42a2-a565-9b84431604cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# helper functions and more data preprocessing before we move on to implementing our models.\n",
        "\n",
        "# from train data, collect all unique word types as a set and add 'UNK' to it (unseen words in test data will be turned into 'UNK')\n",
        "vocab_set = list(set([word for sent in train_data for word in sent])) + ['UNK']\n",
        "num_vocabs = len(vocab_set)\n",
        "print(\"number of word types (including 'UNK'):\", num_vocabs)\n",
        "print(\"the first couple and last couple of words in the vocabulary set:\", vocab_set[0:2] +  vocab_set[-2:])\n",
        "\n",
        "vocab2id = {v : i for i, v in enumerate(vocab_set)}\n",
        "\n",
        "#  collect all tag (class) types and assign an unique id to each of them. (here there won't be a unseen tag type in test data)\n",
        "tag_set = list(set([tag for tag_seq in train_tags for tag in tag_seq]))\n",
        "num_tags = len(tag_set)\n",
        "print(\"number of tag types:\", num_tags)\n",
        "print()\n",
        "\n",
        "# assign each tag type a unique id, also create the inverse dict of tag2id (required during evaluation)\n",
        "tag2id = {t : i for i, t in enumerate(tag_set)} \n",
        "id2tag = {i : t for t, i in tag2id.items()}\n",
        "\n",
        "# apply one-hot encoding to data.\n",
        "train_data_oh_list = [util.one_hot_encoding(sent, vocab2id, vocab_set) for sent in train_data]\n",
        "# print(\"oh data[0] - len:\", len(train_data_oh_list[0]), \"shape:\", train_data_oh_list[0].shape)\n",
        "\n",
        "# transform tag names into ids\n",
        "train_tags_id_list = [util.encoding_idx(tag_seq, tag2id) for tag_seq in train_tags]\n",
        "# print(\"list len, tag data:\", len(train_tags_id_list))\n",
        "\n",
        "# train_data_oh_list should now be a list of 2d-tensors, each has shape (sent_len, num_vocabs)\n",
        "# Note that to utilize the `shape` attribute, each element in the list should already be a torch tensor.\n",
        "print(\"first sentence has shape: %s\" % str(train_data_oh_list[0].shape))\n",
        "print(\"fifth sentence has shape: %s\" % str(train_data_oh_list[4].shape))\n",
        "\n",
        "# train_tags_id_list is a list of 1d-tensors, each that has shape (sent_len,)\n",
        "print(\"first tag sequence has shape: %s\" % train_tags_id_list[0].shape)\n",
        "print(\"fifth tag sequence has shape: %s\" % train_tags_id_list[4].shape)\n",
        "print()\n",
        "\n",
        "\n",
        "# Apply same conversion to test dataset.\n",
        "test_data_oh_list = [util.one_hot_encoding(sent, vocab2id, vocab_set) for sent in test_data]\n",
        "test_tags_id_list = [util.encoding_idx(tag_seq, tag2id) for tag_seq in test_tags]\n",
        "# print(\"list len, oh test:\", len(test_data_oh_list))\n",
        "# print(\"list len, tag test:\", len(test_tags_id_list))\n",
        "# print(\"first sentence has shape: %s\" % str(test_data_oh_list[0].shape))\n",
        "# print(\"fifth sentence has shape: %s\" % str(test_data_oh_list[4].shape))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of word types (including 'UNK'): 3805\n",
            "the first couple and last couple of words in the vocabulary set: ['romana', 'already', 'pleas', 'UNK']\n",
            "number of tag types: 17\n",
            "\n",
            "first sentence has shape: torch.Size([6, 3805])\n",
            "fifth sentence has shape: torch.Size([12, 3805])\n",
            "first tag sequence has shape: 6\n",
            "fifth tag sequence has shape: 12\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7gCDSGGdfeZ",
        "colab_type": "text"
      },
      "source": [
        "#### **LSTM**\n",
        "\n",
        "We implement a vanilla LSTM from scratch, then train it and evaluate its performance on the NER task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m37BjwIIef15",
        "colab_type": "text"
      },
      "source": [
        "##### **LSTM architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_t2jPVDd3bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_NER(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size        \n",
        "\n",
        "    self.lstm_ner = nn.LSTM(self.input_size, self.hidden_size)\n",
        "    self.output = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "\n",
        "  def forward(self, input, hidden, memory):\n",
        "    \"\"\"\n",
        "    The `forward` function just performs one step of update and output logits before softmax.\n",
        "\n",
        "    `input` is a 2d-tensor of shape (1, input_size);\n",
        "    `hidden` and `memory` are both 2d-tensors of shape (1, hidden_size), representing the hidden and memory states of the previous time step.\n",
        "    \"\"\"\n",
        "\n",
        "    output_lstm, hidden = self.lstm_ner(input, (hidden, memory))\n",
        "    output = self.output(output_lstm)\n",
        "    \n",
        "    return output, hidden\n",
        "\n",
        "  def init_state(self):\n",
        "    \"\"\"     # initialize hidden and memory states.\"\"\"\n",
        "    return (torch.zeros( (1, 1, hidden_size), dtype = torch.float).to(device), torch.zeros( (1, 1, hidden_size), dtype = torch.float).to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxQfXsM0dz4m",
        "colab_type": "text"
      },
      "source": [
        "##### **Training**\n",
        "\n",
        "The function $train\\_one\\_sample$, takes a (sentence tensor, tag tensor) pair as input and does one step of the gradient update.\n",
        "\n",
        "The input size is set to the vocbulary size of the dataset, the size of the hidden state is set to $128$ and the output size is set to the number of tags in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPrT97TNWkHF",
        "colab_type": "code",
        "outputId": "82a38122-6cbc-4799-a158-b7f7606482f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learning_rate = 1e-3\n",
        "hidden_size = 128\n",
        "\n",
        "\n",
        "model = LSTM_NER(input_size = num_vocabs, hidden_size = hidden_size, output_size = num_tags).to(device)\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Run through a sentence, generate output, compute loss, and perform one gradient update\n",
        "Sentence and tag are represented as a 2d-tensor `sent_tensor` and a 1d-tensor `tag_tensor`, respectively.\n",
        "\"\"\"\n",
        "def train_one_sample(model, sent_tensor, tag_tensor):\n",
        "  hidden, memory = model.init_state()     # initialize state of the model\n",
        "  loss = torch.zeros(1, dtype = torch.float).to(device)\n",
        "\n",
        "  # print(\"sent_tensor.shape:\", sent_tensor.shape)\n",
        "  sent_tensor = sent_tensor.reshape(sent_tensor.shape[0], 1, sent_tensor.shape[1])\n",
        "  # print(\"sent_tensor.shape:\", sent_tensor.shape)\n",
        "\n",
        "  output, _ = model(sent_tensor, hidden, memory)\n",
        "\n",
        "  # print(\"output.shape:\", output.shape, \"tag_tensor.shape:\", tag_tensor.shape)\n",
        "  output= output.reshape(output.shape[0], output.shape[2])\n",
        "  # print(\"output.shape:\", output.shape)\n",
        "\n",
        "  loss = criterion(output, tag_tensor)\n",
        "\n",
        "  # print(sent_tensor.device, tag_tensor.device, hidden.device, outputs.device, (torch.cuda.LongTensor([tag_tensor[0]]).to(device)).device)\n",
        "\n",
        "  # for idx in range(sent_tensor.shape[0]):\n",
        "  #   # print(model.hidden.weight.grad, model.output.weight.grad)\n",
        "  #   outputs, hidden, memory = model(sent_tensor[idx].reshape(1, sent_tensor.shape[1]), hidden, memory)\n",
        "  #   loss = loss + criterion(outputs, torch.LongTensor([tag_tensor[idx]]).to(device))\n",
        "      \n",
        "  # loss = loss / len(tag_tensor)   # average the loss over all tags in the sentance\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return output, loss.item()\n",
        "\n",
        "\n",
        "# main training loop for the lstm\n",
        "num_epochs = 10\n",
        "iter_count = 0\n",
        "print_every = 1000\n",
        "plot_every = 50\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "b_calc_grad_norm = False # set to true if we want to analyze how the gradient changes over training\n",
        "\n",
        "if b_calc_grad_norm:\n",
        "  current_grad_norm = 0\n",
        "  all_grad_norms = []\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "model.train()\n",
        " \n",
        "for idx_epoch in range(num_epochs):\n",
        "  for sent_tensor, tag_tensor in zip(train_data_oh_list, train_tags_id_list):\n",
        "    sent_tensor = sent_tensor.to(device)\n",
        "    tag_tensor = tag_tensor.to(device)\n",
        "\n",
        "    output, loss = train_one_sample(model, sent_tensor, tag_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "\n",
        "    if b_calc_grad_norm:\n",
        "      grad = torch.FloatTensor( (1, 1)).to(device)\n",
        "      \n",
        "      for param in model.parameters():\n",
        "        grad = torch.cat( (grad, torch.reshape(param.grad, (-1, ))))\n",
        "      \n",
        "      current_grad_norm += torch.norm(grad.to(\"cpu\"), 2)\n",
        "\n",
        "    if iter_count % print_every == 0:\n",
        "      if b_calc_grad_norm:\n",
        "        print(\"epoch: {}, iteration: {}, time: {}, loss: {:0.4f}, grad_norm: {:0.4f}\".format(idx_epoch, iter_count, util.time_since(start), loss, torch.norm(grad.to(\"cpu\"), 2)))\n",
        "      else:\n",
        "        print(\"epoch: {}, iteration: {}, time: {}, loss: {:0.4f}\".format(idx_epoch, iter_count, util.time_since(start), loss))\n",
        "\n",
        "\n",
        "    # add current loss avg to list of losses\n",
        "    if iter_count % plot_every == 0 and iter_count > 0:\n",
        "      all_losses.append(current_loss / plot_every)\n",
        "      current_loss = 0\n",
        "      \n",
        "      if b_calc_grad_norm: \n",
        "        all_grad_norms.append(current_grad_norm / plot_every)\n",
        "        current_grad_norm = 0\n",
        "\n",
        "    iter_count += 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, iteration: 0, time: 0m 0s, loss: 2.8441\n",
            "epoch: 0, iteration: 1000, time: 0m 2s, loss: 2.6534\n",
            "epoch: 0, iteration: 2000, time: 0m 4s, loss: 0.6168\n",
            "epoch: 0, iteration: 3000, time: 0m 7s, loss: 2.1126\n",
            "epoch: 0, iteration: 4000, time: 0m 9s, loss: 1.4473\n",
            "epoch: 0, iteration: 5000, time: 0m 12s, loss: 0.1140\n",
            "epoch: 0, iteration: 6000, time: 0m 14s, loss: 0.4748\n",
            "epoch: 0, iteration: 7000, time: 0m 17s, loss: 0.5433\n",
            "epoch: 1, iteration: 8000, time: 0m 19s, loss: 0.4170\n",
            "epoch: 1, iteration: 9000, time: 0m 22s, loss: 0.8285\n",
            "epoch: 1, iteration: 10000, time: 0m 24s, loss: 0.2111\n",
            "epoch: 1, iteration: 11000, time: 0m 27s, loss: 0.4019\n",
            "epoch: 1, iteration: 12000, time: 0m 29s, loss: 0.0276\n",
            "epoch: 1, iteration: 13000, time: 0m 31s, loss: 0.0762\n",
            "epoch: 1, iteration: 14000, time: 0m 34s, loss: 0.0208\n",
            "epoch: 1, iteration: 15000, time: 0m 36s, loss: 1.1798\n",
            "epoch: 2, iteration: 16000, time: 0m 39s, loss: 0.2719\n",
            "epoch: 2, iteration: 17000, time: 0m 41s, loss: 0.0115\n",
            "epoch: 2, iteration: 18000, time: 0m 44s, loss: 0.0495\n",
            "epoch: 2, iteration: 19000, time: 0m 46s, loss: 0.0159\n",
            "epoch: 2, iteration: 20000, time: 0m 49s, loss: 0.9282\n",
            "epoch: 2, iteration: 21000, time: 0m 51s, loss: 0.0760\n",
            "epoch: 2, iteration: 22000, time: 0m 53s, loss: 0.1927\n",
            "epoch: 3, iteration: 23000, time: 0m 56s, loss: 0.1680\n",
            "epoch: 3, iteration: 24000, time: 0m 58s, loss: 0.0051\n",
            "epoch: 3, iteration: 25000, time: 1m 1s, loss: 0.0297\n",
            "epoch: 3, iteration: 26000, time: 1m 3s, loss: 0.3259\n",
            "epoch: 3, iteration: 27000, time: 1m 6s, loss: 0.0096\n",
            "epoch: 3, iteration: 28000, time: 1m 8s, loss: 0.0142\n",
            "epoch: 3, iteration: 29000, time: 1m 11s, loss: 1.5959\n",
            "epoch: 3, iteration: 30000, time: 1m 13s, loss: 0.0390\n",
            "epoch: 4, iteration: 31000, time: 1m 16s, loss: 0.0067\n",
            "epoch: 4, iteration: 32000, time: 1m 18s, loss: 0.0031\n",
            "epoch: 4, iteration: 33000, time: 1m 20s, loss: 0.0950\n",
            "epoch: 4, iteration: 34000, time: 1m 23s, loss: 0.0262\n",
            "epoch: 4, iteration: 35000, time: 1m 25s, loss: 0.4255\n",
            "epoch: 4, iteration: 36000, time: 1m 28s, loss: 0.0494\n",
            "epoch: 4, iteration: 37000, time: 1m 30s, loss: 0.1330\n",
            "epoch: 4, iteration: 38000, time: 1m 33s, loss: 0.1295\n",
            "epoch: 5, iteration: 39000, time: 1m 35s, loss: 0.0080\n",
            "epoch: 5, iteration: 40000, time: 1m 38s, loss: 0.4048\n",
            "epoch: 5, iteration: 41000, time: 1m 40s, loss: 0.0041\n",
            "epoch: 5, iteration: 42000, time: 1m 43s, loss: 0.0273\n",
            "epoch: 5, iteration: 43000, time: 1m 45s, loss: 0.0126\n",
            "epoch: 5, iteration: 44000, time: 1m 48s, loss: 0.0031\n",
            "epoch: 5, iteration: 45000, time: 1m 50s, loss: 0.3695\n",
            "epoch: 6, iteration: 46000, time: 1m 53s, loss: 0.5116\n",
            "epoch: 6, iteration: 47000, time: 1m 55s, loss: 0.0289\n",
            "epoch: 6, iteration: 48000, time: 1m 58s, loss: 0.4964\n",
            "epoch: 6, iteration: 49000, time: 2m 0s, loss: 0.0122\n",
            "epoch: 6, iteration: 50000, time: 2m 3s, loss: 0.0050\n",
            "epoch: 6, iteration: 51000, time: 2m 5s, loss: 0.0650\n",
            "epoch: 6, iteration: 52000, time: 2m 8s, loss: 0.0502\n",
            "epoch: 6, iteration: 53000, time: 2m 10s, loss: 0.0181\n",
            "epoch: 7, iteration: 54000, time: 2m 12s, loss: 0.0577\n",
            "epoch: 7, iteration: 55000, time: 2m 15s, loss: 0.0087\n",
            "epoch: 7, iteration: 56000, time: 2m 17s, loss: 0.0458\n",
            "epoch: 7, iteration: 57000, time: 2m 20s, loss: 0.0158\n",
            "epoch: 7, iteration: 58000, time: 2m 22s, loss: 0.0239\n",
            "epoch: 7, iteration: 59000, time: 2m 25s, loss: 0.2608\n",
            "epoch: 7, iteration: 60000, time: 2m 27s, loss: 0.0049\n",
            "epoch: 7, iteration: 61000, time: 2m 30s, loss: 0.0086\n",
            "epoch: 8, iteration: 62000, time: 2m 32s, loss: 0.0608\n",
            "epoch: 8, iteration: 63000, time: 2m 35s, loss: 0.0815\n",
            "epoch: 8, iteration: 64000, time: 2m 37s, loss: 0.0088\n",
            "epoch: 8, iteration: 65000, time: 2m 40s, loss: 0.3746\n",
            "epoch: 8, iteration: 66000, time: 2m 42s, loss: 0.0366\n",
            "epoch: 8, iteration: 67000, time: 2m 45s, loss: 0.0003\n",
            "epoch: 8, iteration: 68000, time: 2m 47s, loss: 0.1764\n",
            "epoch: 9, iteration: 69000, time: 2m 50s, loss: 0.0731\n",
            "epoch: 9, iteration: 70000, time: 2m 53s, loss: 0.0058\n",
            "epoch: 9, iteration: 71000, time: 2m 55s, loss: 0.0013\n",
            "epoch: 9, iteration: 72000, time: 2m 58s, loss: 0.0863\n",
            "epoch: 9, iteration: 73000, time: 3m 0s, loss: 0.0236\n",
            "epoch: 9, iteration: 74000, time: 3m 3s, loss: 0.0015\n",
            "epoch: 9, iteration: 75000, time: 3m 5s, loss: 0.0230\n",
            "epoch: 9, iteration: 76000, time: 3m 8s, loss: 0.0009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wicccX-eNZu",
        "colab_type": "text"
      },
      "source": [
        "##### **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwsFjcYBmWL_",
        "colab_type": "text"
      },
      "source": [
        "We plot the learning curve. We also evaluate the model on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eYuprdb3d1i",
        "colab_type": "text"
      },
      "source": [
        "###### **Learning Curve**\n",
        "\n",
        "We plot the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KPXOHLheN7G",
        "colab_type": "code",
        "outputId": "7dd0ed30-ba9d-4391-b2d0-a4b149ff6f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# plot the learning curve. The x-axis is the training iterations and the y-axis is the training loss. The loss should be going down.\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "x_axis_pts = np.array([idx for idx, _ in enumerate(all_losses)])\n",
        "\n",
        "if b_calc_grad_norm:\n",
        "  fig, (ax_1, ax_2) = plt.subplots(1, 2)\n",
        "  \n",
        "  ax_1.plot(x_axis_pts, all_losses)\n",
        "  ax_1.set_xlabel(\"iteration\")\n",
        "  ax_1.set_ylabel(\"loss\")\n",
        "  ax_1.set_title(\"learning curve\");\n",
        "\n",
        "  ax_2.plot(x_axis_pts, all_grad_norms)\n",
        "  ax_2.set_xlabel(\"iteration\")\n",
        "  ax_2.set_ylabel(\"norm of the gradient\")\n",
        "  ax_2.set_title(\"gradient descent\");\n",
        "\n",
        "else:\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(x_axis_pts, all_losses)\n",
        "  ax.set_xlabel(\"iteration\")\n",
        "  ax.set_ylabel(\"loss\")\n",
        "  ax.set_title(\"learning curve\");"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P90yPixR3ojS",
        "colab_type": "text"
      },
      "source": [
        "###### **Inference**\n",
        "\n",
        "We use the trained model to run inference on the test dataset and compute the [precision, recall](https://en.wikipedia.org/wiki/Precision_and_recall) and [f1 score](https://en.wikipedia.org/wiki/F1_score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVj-JXcOmkBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53101bf0-fc17-42c5-d944-a451a7311830"
      },
      "source": [
        "# Make prediction for one sentence.\n",
        "def predict(model, sent_tensor):\n",
        "  hidden, memory = model.init_state()\n",
        "\n",
        "  predicted_tag_id = []\n",
        "\n",
        "  sent_tensor = sent_tensor.reshape(sent_tensor.shape[0], 1, sent_tensor.shape[1])\n",
        "  output, _ = model(sent_tensor, hidden, memory)\n",
        "  output = output.reshape(output.shape[0], output.shape[2])\n",
        "  predicted_tag_id = np.argmax(output.detach().cpu().numpy(), axis = 1)\n",
        "\n",
        "  return predicted_tag_id\n",
        " \n",
        " \n",
        "model.eval()\n",
        "predicted_tags = []\n",
        " \n",
        "for sent_tensor in test_data_oh_list:\n",
        "    sent_tensor = sent_tensor.to(device)\n",
        "    predicted_tag_id = predict(model, sent_tensor)\n",
        "    predicted_tags.append([id2tag[idx] for idx in predicted_tag_id])\n",
        "  \n",
        "   \n",
        "# precision, recall, and f1 score\n",
        "\n",
        "# Example: true_tag_list/predicted_tag_list:\n",
        "#   [[‘O’, ‘O’, ‘I’, ‘N’, ...]\n",
        "#    [‘I’, ‘I’, ‘O’, ‘N’, ...]],\n",
        "precision, recall, f1_score = util.evaluate_result(test_tags, predicted_tags)\n",
        "print(\"precision: {:0.4f}, recall: {:0.4f}, f1 score: {:0.4f}\".format(precision, recall, f1_score))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.7501, recall: 0.7531, f1 score: 0.7449\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}