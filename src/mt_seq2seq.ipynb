{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "15vgPnuxKM2A",
        "zDJjmvZfHV_l",
        "kb5gQEp7oVdi",
        "8Oz3Kc4QKyEP",
        "AH0VdHE2_x1k",
        "M06QOTbCALGy",
        "YmHOPtB8VKwS"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fOArV2r9Piz",
        "colab_type": "text"
      },
      "source": [
        "#### **Machine Translation with a Sequence-to-Sequence Model**\n",
        "\n",
        "We explore the Machine Translation (MT) task using RNN-based sequence-to-sequence (seq2seq) models.\n",
        "\n",
        "We will use a Vietnamese-English dataset from IWSLT'15. The task is to translate a Vietnamese sentence into English.\n",
        "\n",
        "The [framework](https://github.com/lingo-mit/6864-hw2/blob/master/6864_hw2b.ipynb) for the code was provided by the TAs for MIT 6.864 (Advanced Natural Language Processing), Spring 2020.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15vgPnuxKM2A",
        "colab_type": "text"
      },
      "source": [
        "#### **Setup**\n",
        "\n",
        "Import required libraries and read in the dataset.\n",
        "\n",
        "If the dataset is not downloaded, we download it and place it under the \"data\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwd4nva1Q9oC",
        "colab_type": "code",
        "outputId": "c8054998-fd85-4ca6-d24b-d0056c4ed6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "!pip install sacrebleu\n",
        "import sacrebleu\n",
        "\n",
        "import util\n",
        "from util import MTDataset\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\"   # use gpu!\n",
        "\n",
        "\n",
        "# util.get_dataset(\"en_vi_iwslt_15\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.6)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.6.0)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (0.996.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJjmvZfHV_l",
        "colab_type": "text"
      },
      "source": [
        "#### **Data Preprocessing**\n",
        "\n",
        "We do some simple data preprocessing and show some data statistics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfkQGqV30hgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "7a89dd0c-022e-4961-d48f-5fa7b3b42e28"
      },
      "source": [
        "# Note in the vocab files for English and Vietnamese, each line is a word in the vocabulary,\n",
        "# that's why we set \"type\" to sentence\n",
        "src_vocab_set = util.read_file_txt(os.path.join(\"../data\", \"vocab.vi\"), encoding = None, type = \"sentence\")\n",
        "trg_vocab_set = util.read_file_txt(os.path.join(\"../data\", \"vocab.en\"), encoding = None, type = \"sentence\")\n",
        "\n",
        "train_src_sentences_list = util.read_file_txt(os.path.join(\"../data\", \"train.vi\"))\n",
        "train_trg_sentences_list = util.read_file_txt(os.path.join(\"../data\", \"train.en\"))\n",
        "assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n",
        "\n",
        "test_src_sentences_list = util.read_file_txt(os.path.join(\"../data\", \"tst2013.vi\"))\n",
        "test_trg_sentences_list = util.read_file_txt(os.path.join(\"../data\", \"tst2013.en\"))\n",
        "assert len(test_src_sentences_list) == len(test_trg_sentences_list)\n",
        "\n",
        "\n",
        "train_src_sentences_list, train_trg_sentences_list = util.filter_data(train_src_sentences_list, train_trg_sentences_list)\n",
        "test_src_sentences_list, test_trg_sentences_list = util.filter_data(test_src_sentences_list, test_trg_sentences_list)\n",
        "\n",
        "# We take 10% of training data as validation set.\n",
        "num_val = int(len(train_src_sentences_list) * 0.1)\n",
        "val_src_sentences_list = train_src_sentences_list[:num_val]\n",
        "val_trg_sentences_list = train_trg_sentences_list[:num_val]\n",
        "train_src_sentences_list = train_src_sentences_list[num_val:]\n",
        "train_trg_sentences_list = train_trg_sentences_list[num_val:]\n",
        "\n",
        "# Show some data stats\n",
        "print(\"Number of training (src, trg) sentence pairs: %d\", len(train_src_sentences_list))\n",
        "print(\"Number of validation (src, trg) sentence pairs: %d\", len(val_src_sentences_list))\n",
        "print(\"Number of testing (src, trg) sentence pairs: %d\", len(test_src_sentences_list))\n",
        "\n",
        "src_vocab_set = ['<pad>'] + src_vocab_set\n",
        "trg_vocab_set = ['<pad>'] + trg_vocab_set\n",
        "print(\"Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\", len(src_vocab_set))\n",
        "print(\"Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\", len(trg_vocab_set))\n",
        "\n",
        "length = [len(sent) for sent in train_src_sentences_list]\n",
        "print('Training sentence avg. length: %d ', np.mean(length))\n",
        "print('Training sentence length at 95-percentile: %d', np.percentile(length, 95))\n",
        "print(\"\\n\")\n",
        "\n",
        "print('Training sentence length distribution (x-axis is length range and y-axis is count)\\n')\n",
        "plt.hist(length, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('Example Vietnamese input: ' + str(train_src_sentences_list[1]))\n",
        "print('Its target English output: ' + str(train_trg_sentences_list[1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training (src, trg) sentence pairs: %d 23322\n",
            "Number of validation (src, trg) sentence pairs: %d 2591\n",
            "Number of testing (src, trg) sentence pairs: %d 233\n",
            "Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d 7710\n",
            "Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d 17192\n",
            "Training sentence avg. length: %d  32.04364977274676\n",
            "Training sentence length at 95-percentile: %d 46.0\n",
            "\n",
            "\n",
            "Training sentence length distribution (x-axis is length range and y-axis is count)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAWPBrMLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Example Vietnamese input: Riêng tôi , tôi mê ý tưởng này cực kì .\n",
            "Its target English output: For me , I really love this idea .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb5gQEp7oVdi",
        "colab_type": "text"
      },
      "source": [
        "#### **Encoder**\n",
        "\n",
        "RNN seq2seq models consists of an encoder RNN and a decoder RNN.\n",
        "In a vanilla seq2seq model where there is no attention mechanism between encoder and decoder, the encoder aims to compress the information contained in the entire input sequence into a single vector and pass it to decoder.\n",
        "\n",
        "We start with implementing the encoder, which is just a simple RNN. Here we use the [GRU](https://pytorch.org/docs/stable/nn.html#gru) architecture for the RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnwVGDVkoPt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dropout = 0.00):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "      - `input_size`: an int representing the RNN input size.\n",
        "      - `hidden_size`: an int representing the RNN hidden size.\n",
        "      - `dropout`: a float representing the dropout rate during training.\n",
        "         Note that for 1-layer RNN this has no effect since dropout only applies to outputs of intermediate layers.\n",
        "    \"\"\"\n",
        "    \n",
        "    super().__init__()\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True, dropout = dropout, bidirectional = False)\n",
        "\n",
        "  def forward(self, inputs, lengths):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of source sentences.\n",
        "      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence lengths of `inputs`.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape (batch_size, max_seq_length, hidden_size).\n",
        "      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n",
        "    \"\"\"\n",
        "    # print(\"inputs.shape:\", inputs.shape)\n",
        "    # print(\"lengths.shape:\", lengths.shape)\n",
        "\n",
        "    packed_input = pack_padded_sequence(inputs, lengths, batch_first = True, enforce_sorted = False)\n",
        "    outputs, finals = self.rnn(packed_input)\n",
        "    outputs, outputs_len = pad_packed_sequence(outputs, batch_first = True)\n",
        "\n",
        "    return outputs, finals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oz3Kc4QKyEP",
        "colab_type": "text"
      },
      "source": [
        "#### **Decoder**\n",
        "\n",
        "A RNN decoder that uses the encoder's last hidden state to initialize its initial hidden state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYT0BlfYUJXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  \"\"\"An RNN decoder without attention.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dropout = 0.00):\n",
        "    \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True, dropout = dropout, bidirectional = False)\n",
        "\n",
        "    \n",
        "  def forward(self, inputs, encoder_finals, hidden=None, max_len = None):\n",
        "    \"\"\"Unroll the decoder one step at a time.\n",
        "\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of target\n",
        "          sentences (for teacher-forcing during training).\n",
        "      - `encoder_finals`: a 3d-tensor of shape\n",
        "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
        "          encoder hidden states used to initialize the initial decoder hidden\n",
        "          states.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the value to be used to initialize the initial decoder hidden states.\n",
        "          If None, then use `encoder_finals`.\n",
        "      - `max_len`: an int representing the maximum decoding length.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the raw\n",
        "          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n",
        "          We will convert it later in a `Generator` below.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
        "          representing the last decoder hidden state.\n",
        "    \"\"\"\n",
        "\n",
        "    # The maximum number of steps to unroll the RNN.\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    # Initialize decoder hidden state.\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    outputs, hidden = self.rnn(inputs, hidden)\n",
        "\n",
        "    # return hidden, outputs\n",
        "    return outputs, hidden\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\" Use encoder final hidden state to initialize decoder's first hidden state.\"\"\"\n",
        "    decoder_init_hiddens = encoder_finals\n",
        "\n",
        "    return decoder_init_hiddens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH0VdHE2_x1k",
        "colab_type": "text"
      },
      "source": [
        "#### **Encoder-Decoder**\n",
        "\n",
        "We define the high level encoder-decoder class to wrap up sub-models, including encoder, decoder, generator, and src/trg embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBaAYB_oHxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"A standard Encoder-Decoder architecture without attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `encoder`: an `Encoder` object.\n",
        "      - `decoder`: an `Decoder` object.\n",
        "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "          input (source) sentences.\n",
        "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
        "          output (target) sentences.\n",
        "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
        "          the next code cell.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    \"\"\"Take in and process masked source and target sequences.\n",
        "\n",
        "    Inputs:\n",
        "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of source sentences of word ids.\n",
        "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of target sentences of word ids.\n",
        "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
        "        sequence length of `src_ids`.\n",
        "\n",
        "    Returns the decoder outputs, see the above cell.\n",
        "    \"\"\"\n",
        "    _, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    # trg_ids_new = trg_ids[:, :-1]\n",
        "    # print(\"trg_ids:\", trg_ids.shape, \"trg_ids_new\", trg_ids_new.shape)\n",
        "    decoder_outputs, decoder_hiddens = self.decode(encoder_finals, trg_ids[:, :-1])\n",
        "\n",
        "    return decoder_outputs, decoder_hiddens\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, encoder_finals, trg_ids, decoder_hidden = None):\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_finals, decoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M06QOTbCALGy",
        "colab_type": "text"
      },
      "source": [
        "#### **Generator**\n",
        "\n",
        "It simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaHdVcF1KPmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  \n",
        "  \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "  def __init__(self, hidden_size, vocab_size):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(hidden_size, vocab_size, bias = False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIpNlKtK8l_",
        "colab_type": "text"
      },
      "source": [
        "#### **Training and Testing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmHOPtB8VKwS",
        "colab_type": "text"
      },
      "source": [
        "##### **Dataloading**\n",
        "\n",
        "Apply the dataloader to the dataset. The dataloader provides a convenient way to iterate through the whole dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr_kz4amVFgX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJrXO7nCjzBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# note - the size of the training set may be reduced by setting a smaller value for \"sampling\"\n",
        "train_set = util.MTDataset(train_src_sentences_list, src_vocab_set, train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "train_data_loader = data.DataLoader(train_set, batch_size=batch_size, num_workers=8, shuffle=True)\n",
        "\n",
        "val_set = util.MTDataset(val_src_sentences_list, src_vocab_set, val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "val_data_loader = data.DataLoader(val_set, batch_size=batch_size, num_workers=8, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWaiu7wNBX7x",
        "colab_type": "text"
      },
      "source": [
        "##### **Training**\n",
        "\n",
        "The main functions for training, here we use perplexity to evaluate the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGa-L1qp13q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "cdd527f2-6592-4097-a4a7-2575beb0774b"
      },
      "source": [
        "def run_epoch(data_loader, model, loss_compute, print_every, start_time):\n",
        "  \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "  total_tokens = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for idx, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n",
        "    # We define some notations here to help you understand the loaded tensor\n",
        "    # shapes:\n",
        "    #   `B`: batch size\n",
        "    #   `T`: max sequence length of source sentences\n",
        "    #   `L`: max sequence length of target sentences; due to our preprocessing\n",
        "    #        in the beginning, `L` == `T` == 50\n",
        "    # An example of `src_ids_BxT` (when B = 2):\n",
        "    #   [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n",
        "    #    [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n",
        "    # The corresponding `src_lengths_B` would be [47, 49].\n",
        "    # Note that SOS_INDEX == 2, EOS_INDEX == 3, and PAD_INDEX = 0.\n",
        "\n",
        "    src_ids_BxT = src_ids_BxT.to(device)\n",
        "    src_lengths_B = src_lengths_B.to(device)\n",
        "    trg_ids_BxL = trg_ids_BxL.to(device)\n",
        "    del trg_lengths_B   # unused\n",
        "\n",
        "    # print(\"src_ids_BxT:\", src_ids_BxT.shape)\n",
        "    # print(\"trg_ids_BxL:\", trg_ids_BxL.shape)\n",
        "    # print(\"src_lengths_B:\", src_lengths_B.shape)\n",
        "\n",
        "    # _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
        "    output, _ = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
        "    # print(\"output.shape:\", output.shape)\n",
        "\n",
        "    loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:], norm=src_ids_BxT.size(0))\n",
        "    total_loss += loss\n",
        "    total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
        "\n",
        "\n",
        "    if model.training and idx % print_every == 0:\n",
        "      print(\"iteration: {}, time: {}, loss: {:0.4f}\".format(idx, util.time_since(start_time), loss / src_ids_BxT.size(0)))\n",
        "\n",
        "  return math.exp(total_loss / float(total_tokens))\n",
        "\n",
        "\n",
        "PAD_INDEX = 0\n",
        "\n",
        "def train(model, num_epochs, learning_rate, print_every):\n",
        "  criterion = nn.NLLLoss(reduction = \"sum\", ignore_index = PAD_INDEX)   # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when computing the loss.\n",
        "  optim = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "  dev_ppls = []   # keep track of dev perplexity for each epoch\n",
        "  start = time.time()\n",
        "\n",
        "  for idx in range(num_epochs):\n",
        "    print(\"epoch\", idx)\n",
        "\n",
        "    model.train()\n",
        "    train_ppl = run_epoch(data_loader = train_data_loader, model = model,\n",
        "                          loss_compute = util.SimpleLossCompute(model, criterion, optim),\n",
        "                          print_every = print_every, start_time = start)\n",
        "         \n",
        "    model.eval()\n",
        "    with torch.no_grad():      \n",
        "      dev_ppl = run_epoch(data_loader = val_data_loader, model = model,\n",
        "                          loss_compute = util.SimpleLossCompute(model, criterion, None),\n",
        "                          print_every = print_every, start_time = start)\n",
        "      \n",
        "      print(\"validation perplexity: {:0.4f}\".format(dev_ppl))\n",
        "      dev_ppls.append(dev_ppl)\n",
        "        \n",
        "  return dev_ppls\n",
        "\n",
        "\n",
        "# Hyperparameters for contructing the encoder-decoder model\n",
        "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
        "hidden_size = 256  # RNN hidden size.\n",
        "dropout = 0.00\n",
        "\n",
        "pure_seq2seq = EncoderDecoder(\n",
        "  encoder = Encoder(embed_size, hidden_size, dropout = dropout),\n",
        "  decoder = Decoder(embed_size, hidden_size, dropout = dropout),\n",
        "  src_embed = nn.Embedding(len(src_vocab_set), embed_size),\n",
        "  trg_embed = nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "  generator = Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "\n",
        "pure_dev_ppls = train(pure_seq2seq, num_epochs = 2, learning_rate = 1e-3, print_every = 100) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "iteration: 0, time: 0m 2s, loss: 317.1935\n",
            "iteration: 100, time: 0m 41s, loss: 54.8127\n",
            "validation perplexity: 4.5010\n",
            "epoch 1\n",
            "iteration: 0, time: 1m 21s, loss: 51.1021\n",
            "iteration: 100, time: 1m 58s, loss: 49.0548\n",
            "validation perplexity: 4.0048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRsfDg0wCa7U",
        "colab_type": "text"
      },
      "source": [
        "#### **Evaluation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuUxzn7mXkdh",
        "colab_type": "text"
      },
      "source": [
        "##### **Perplexity**\n",
        "\n",
        "Plot the perplexity graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTApnlT53YvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "993a2891-ccae-4470-ddcc-5ec27f66ee6d"
      },
      "source": [
        "util.plot_perplexity(pure_dev_ppls)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncwoCEZEwpyAQEQlzCgIRkTD3f0Q/dTSUe47/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guoYmchOXrRp",
        "colab_type": "text"
      },
      "source": [
        "##### **Decoding**\n",
        "\n",
        "Decode the model output. For simplicity, we use greedy search here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1HTqYwy6-yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_decode(model, src_ids, src_lengths, max_len):\n",
        "  \"\"\"Greedily decode a sentence for EncoderDecoder.\"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "\n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "      hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n",
        "      prob = model.generator(outputs[:, -1])\n",
        "\n",
        "    _, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "\n",
        "  # Cut off everything starting from </s>.\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "  return output\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab):\n",
        "  return [vocab[i] for i in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_5go3VxJZKh",
        "colab_type": "text"
      },
      "source": [
        "Print the top 3 examples from the data loader by applying the greedy decoder. Here we use the validation dataset to print examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3m4optFrb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "9d291666-0577-43da-a2db-6d61a7305e79"
      },
      "source": [
        "MAX_SENT_LENGTH_PLUS_SOS_EOS = 50\n",
        "SOS_INDEX = 2\n",
        "EOS_INDEX = 3\n",
        "NUM_EXAMPLES = 3\n",
        "SRC_VOCAB_SET = src_vocab_set\n",
        "TRG_VOCAB_SET = trg_vocab_set\n",
        "\n",
        "def print_examples(model, data_loader):\n",
        "  \"\"\"Prints NUM_EXAMPLES. Assumes a batch size of 1.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for idx, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
        "    result = greedy_decode(model, src_ids.to(device), src_lengths.to(device), max_len = MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    print(\"example \", idx + 1)\n",
        "    print(\"src: \", \" \".join(lookup_words(src_ids, vocab = SRC_VOCAB_SET)))\n",
        "    print(\"trg: \", \" \".join(lookup_words(trg_ids, vocab = TRG_VOCAB_SET)))\n",
        "    print(\"pred: \", \" \".join(lookup_words(result, vocab = TRG_VOCAB_SET)))\n",
        "    print()\n",
        "\n",
        "    if idx == NUM_EXAMPLES - 1:\n",
        "      break\n",
        "\n",
        "\n",
        "example_set = util.MTDataset(val_src_sentences_list, src_vocab_set, val_trg_sentences_list, trg_vocab_set)\n",
        "example_data_loader = data.DataLoader(example_set, batch_size = 1, num_workers = 1, shuffle = False)\n",
        "\n",
        "print_examples(pure_seq2seq, example_data_loader)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example  1\n",
            "src:  C h <unk> n <unk> <unk> t ô i <unk> c h o <unk> n ó <unk> n ổ <unk> v à <unk> x e m <unk> x <unk> t <unk> t ừ n <unk> <unk> m ả n h <unk> n h <unk> <unk> .\n",
            "trg:  W <unk> <unk> b l o <unk> <unk> i <unk> <unk> <unk> <unk> <unk> a n d <unk> l o o <unk> <unk> a <unk> <unk> <unk> <unk> <unk> <unk> <unk> i <unk> <unk> <unk> s <unk> .\n",
            "pred:  W <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "\n",
            "example  2\n",
            "src:  D <unk> <unk> v <unk> y <unk> , <unk> c h <unk> n <unk> <unk> t ô i <unk> v <unk> n <unk> x e m <unk> x <unk> t <unk> t ừ n <unk> <unk> m ả n h <unk> n h <unk> <unk> .\n",
            "trg:  B <unk> <unk> <unk> s <unk> i l l <unk> , <unk> <unk> <unk> <unk> l o o <unk> <unk> a <unk> <unk> <unk> <unk> <unk> <unk> <unk> i <unk> <unk> <unk> s <unk> .\n",
            "pred:  T <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "\n",
            "example  3\n",
            "src:  V à <unk> t ừ <unk> <unk> ư <unk> i <unk> <unk> <unk> t <unk> .\n",
            "trg:  A n d <unk> <unk> <unk> i s <unk> i s <unk> <unk> <unk> <unk> <unk> <unk> o <unk> <unk> <unk> <unk> <unk> <unk> o <unk> <unk> b <unk> l o <unk> <unk> .\n",
            "pred:  A n d <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5pTV5PqJtX4",
        "colab_type": "text"
      },
      "source": [
        "##### **BLEU score**\n",
        "\n",
        "Compute the [BLEU](https://en.wikipedia.org/wiki/BLEU) score, a standard measure to evaluate the translation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XGQYwHRPyne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "765a96fc-6989-420a-f9f5-7ec73459057c"
      },
      "source": [
        "# import sacrebleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def compute_bleu(model, data_loader):\n",
        "  bleu_score = []\n",
        "\n",
        "  model.eval()\n",
        "  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n",
        "    result = greedy_decode(model, src_ids.to(device), src_lengths.to(device), max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    pred = \" \".join(lookup_words(result, vocab = TRG_VOCAB_SET))\n",
        "    targ = \" \".join(lookup_words(trg_ids, vocab = TRG_VOCAB_SET))\n",
        "\n",
        "    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n",
        "\n",
        "  return bleu_score\n",
        "\n",
        "\n",
        "test_set = MTDataset(test_src_sentences_list, SRC_VOCAB_SET, test_trg_sentences_list, TRG_VOCAB_SET, sampling = 1.)\n",
        "test_data_loader = data.DataLoader(test_set, batch_size = 1, num_workers = 8, shuffle = False)\n",
        "\n",
        "print(\"\\nBLEU score: {:0.4f}\".format(np.mean(compute_bleu(pure_seq2seq, test_data_loader))))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 233/233 [00:11<00:00, 20.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BLEU score: 15.1403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}