{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fOArV2r9Piz",
        "colab_type": "text"
      },
      "source": [
        "#### **Sequence-to-Sequence Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA9JfWiK9eoL",
        "colab_type": "text"
      },
      "source": [
        "We explore RNN-based sequence-to-sequence (seq2seq) models to perform machine translation (MT). We will use a Vietnamese-English dataset from IWSLT'15. The task is to translate a Vietnamese sentence into English.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwd4nva1Q9oC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import util\n",
        "from util import MTDataset\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\"   # use gpu!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJjmvZfHV_l",
        "colab_type": "text"
      },
      "source": [
        "#### **Data Preprocessing**\n",
        "\n",
        "1. We download the dataset and place it under the \"data\" directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02RioHPryvOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "util.get_dataset(\"en_vi_iwslt_15\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogFESHAf-6MY",
        "colab_type": "text"
      },
      "source": [
        "2. We do some simple data preprocessing and show some data statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfkQGqV30hgC",
        "colab_type": "code",
        "outputId": "5ab2ebb1-0ed0-4098-fc42-d16fddade491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "src_vocab_set = util.read_vocab_file(os.path.join(\"../data\", \"vocab.vi\"))\n",
        "trg_vocab_set = util.read_vocab_file(os.path.join(\"../data\", \"vocab.en\"))\n",
        "\n",
        "train_src_sentences_list = util.read_sentence_file(os.path.join(\"../data\", \"train.vi\"))\n",
        "train_trg_sentences_list = util.read_sentence_file(os.path.join(\"../data\", \"train.en\"))\n",
        "assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n",
        "\n",
        "test_src_sentences_list = util.read_sentence_file(os.path.join(\"../data\", \"tst2013.vi\"))\n",
        "test_trg_sentences_list = util.read_sentence_file(os.path.join(\"../data\", \"tst2013.en\"))\n",
        "assert len(test_src_sentences_list) == len(test_trg_sentences_list)\n",
        "\n",
        "\n",
        "train_src_sentences_list, train_trg_sentences_list = util.filter_data(train_src_sentences_list, train_trg_sentences_list)\n",
        "test_src_sentences_list, test_trg_sentences_list = util.filter_data(test_src_sentences_list, test_trg_sentences_list)\n",
        "\n",
        "# We take 10% of training data as validation set.\n",
        "num_val = int(len(train_src_sentences_list) * 0.1)\n",
        "val_src_sentences_list = train_src_sentences_list[:num_val]\n",
        "val_trg_sentences_list = train_trg_sentences_list[:num_val]\n",
        "train_src_sentences_list = train_src_sentences_list[num_val:]\n",
        "train_trg_sentences_list = train_trg_sentences_list[num_val:]\n",
        "\n",
        "# Show some data stats\n",
        "print(\"Number of training (src, trg) sentence pairs: %d\", len(train_src_sentences_list))\n",
        "print(\"Number of validation (src, trg) sentence pairs: %d\", len(val_src_sentences_list))\n",
        "print(\"Number of testing (src, trg) sentence pairs: %d\", len(test_src_sentences_list))\n",
        "\n",
        "src_vocab_set = ['<pad>'] + src_vocab_set\n",
        "trg_vocab_set = ['<pad>'] + trg_vocab_set\n",
        "print(\"Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\", len(src_vocab_set))\n",
        "print(\"Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\", len(trg_vocab_set))\n",
        "\n",
        "length = [len(sent) for sent in train_src_sentences_list]\n",
        "print('Training sentence avg. length: %d ', np.mean(length))\n",
        "print('Training sentence length at 95-percentile: %d', np.percentile(length, 95))\n",
        "print(\"\\n\")\n",
        "\n",
        "print('Training sentence length distribution (x-axis is length range and y-axis is count)\\n')\n",
        "plt.hist(length, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('Example Vietnamese input: ' + str(train_src_sentences_list[0]))\n",
        "print('Its target English output: ' + str(train_trg_sentences_list[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training (src, trg) sentence pairs: %d 108748\n",
            "Number of validation (src, trg) sentence pairs: %d 12083\n",
            "Number of testing (src, trg) sentence pairs: %d 1139\n",
            "Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d 7710\n",
            "Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d 17192\n",
            "Training sentence avg. length: %d  20.534373045941074\n",
            "Training sentence length at 95-percentile: %d 42.0\n",
            "\n",
            "\n",
            "Training sentence length distribution (x-axis is length range and y-axis is count)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Example Vietnamese input: ['Adam', 'Sadowsky', 'dàn', 'dựng', '1', 'video', 'âm', 'nhạc', 'hiện', 'tượng', '.']\n",
            "Its target English output: ['Adam', 'Sadowsky', ':', 'How', 'to', 'engineer', 'a', 'viral', 'music', 'video']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb5gQEp7oVdi",
        "colab_type": "text"
      },
      "source": [
        "#### **Encoder**\n",
        "\n",
        "RNN seq2seq models consists of an encoder RNN and a decoder RNN.\n",
        "In a vanilla seq2seq model where there is no attention mechanism between encoder and decoder, the encoder aims to compress the information contained in the entire input sequence into a single vector and pass it to decoder.\n",
        "\n",
        "We start with implementing the encoder, which is just a simple RNN. Here we use the [GRU](https://pytorch.org/docs/stable/nn.html#gru) architecture for the RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnwVGDVkoPt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dropout = 0.00):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "      - `input_size`: an int representing the RNN input size.\n",
        "      - `hidden_size`: an int representing the RNN hidden size.\n",
        "      - `dropout`: a float representing the dropout rate during training. Note\n",
        "          that for 1-layer RNN this has no effect since dropout only applies to\n",
        "          outputs of intermediate layers.\n",
        "    \"\"\"\n",
        "    \n",
        "    super().__init__()\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True, dropout = dropout, bidirectional = False)\n",
        "\n",
        "  def forward(self, inputs, lengths):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of source\n",
        "          sentences.\n",
        "      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n",
        "          lengths of `inputs`.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "        (batch_size, max_seq_length, hidden_size).\n",
        "      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n",
        "      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n",
        "      https://pytorch.org/docs/stable/nn.html#gru\n",
        "    \"\"\"\n",
        "    outputs = None\n",
        "    finals = None\n",
        "    ### Your code here!\n",
        "    outputs, finals = self.rnn(inputs, lengths)\n",
        "\n",
        "\n",
        "    return outputs, finals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oz3Kc4QKyEP",
        "colab_type": "text"
      },
      "source": [
        "#### **Decoder**\n",
        "\n",
        "A RNN decoder that uses the encoder's last hidden state to initialize its initial hidden state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYT0BlfYUJXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  \"\"\"An RNN decoder without attention.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dropout = 0.00):\n",
        "    \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True, dropout = dropout, bidirectional = False)\n",
        "\n",
        "    \n",
        "  def forward(self, inputs, encoder_finals, hidden=None, max_len=None):\n",
        "    \"\"\"Unroll the decoder one step at a time.\n",
        "\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of target\n",
        "          sentences (for teacher-forcing during training).\n",
        "      - `encoder_finals`: a 3d-tensor of shape\n",
        "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
        "          encoder hidden states used to initialize the initial decoder hidden\n",
        "          states.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the value to be used to initialize the initial decoder hidden states.\n",
        "          If None, then use `encoder_finals`.\n",
        "      - `max_len`: an int representing the maximum decoding length.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the raw\n",
        "          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n",
        "          We will convert it later in a `Generator` below.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
        "          representing the last decoder hidden state.\n",
        "    \"\"\"\n",
        "\n",
        "    # The maximum number of steps to unroll the RNN.\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    # Initialize decoder hidden state.\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    outputs = None\n",
        "    ### Your code here!\n",
        "    outputs = self.rnn()\n",
        "\n",
        "\n",
        "    return hidden, outputs\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\" Use encoder final hidden state to initialize decoder's first hidden state.\"\"\"\n",
        "    decoder_init_hiddens = encoder_finals\n",
        "\n",
        "    return decoder_init_hiddens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH0VdHE2_x1k",
        "colab_type": "text"
      },
      "source": [
        "#### **Encoder-Decoder**\n",
        "\n",
        "We define the high level encoder-decoder class to wrap up sub-models, including encoder, decoder, generator, and src/trg embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBaAYB_oHxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"A standard Encoder-Decoder architecture without attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `encoder`: an `Encoder` object.\n",
        "      - `decoder`: an `Decoder` object.\n",
        "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "          input (source) sentences.\n",
        "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
        "          output (target) sentences.\n",
        "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
        "          the next code cell.\n",
        "    \"\"\"\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    \"\"\"Take in and process masked source and target sequences.\n",
        "\n",
        "    Inputs:\n",
        "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of source sentences of word ids.\n",
        "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of target sentences of word ids.\n",
        "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
        "        sequence length of `src_ids`.\n",
        "\n",
        "    Returns the decoder outputs, see the above cell.\n",
        "    \"\"\"\n",
        "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    del encoder_hiddens   # unused\n",
        "    return self.decode(encoder_finals, trg_ids[:, :-1])\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, encoder_finals, trg_ids, decoder_hidden=None):\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_finals, decoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M06QOTbCALGy",
        "colab_type": "text"
      },
      "source": [
        "It simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaHdVcF1KPmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "  def __init__(self, hidden_size, vocab_size):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(hidden_size, vocab_size, bias = False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIpNlKtK8l_",
        "colab_type": "text"
      },
      "source": [
        "#### **Training and Testing**\n",
        "\n",
        "1. Apply the dataloader to the mt dataset. The dataloader provides a convenient way to iterate through the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJrXO7nCjzBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# note - the size of the training set may be reduced by setting a smaller value for \"sampling\"\n",
        "train_set = util.MTDataset(train_src_sentences_list, src_vocab_set, train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "train_data_loader = data.DataLoader(train_set, batch_size=batch_size, num_workers=8, shuffle=True)\n",
        "\n",
        "val_set = util.MTDataset(val_src_sentences_list, src_vocab_set, val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "val_data_loader = data.DataLoader(val_set, batch_size=batch_size, num_workers=8, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWaiu7wNBX7x",
        "colab_type": "text"
      },
      "source": [
        "2. The main functions for training, here we use perplexity to evaluate the performance of the model. Although we provide the training scripts here, we strongly encoureage you to go through and understand the procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGa-L1qp13q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "# class SimpleLossCompute:\n",
        "#   \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "#   def __init__(self, generator, criterion, opt = None):\n",
        "#     self.generator = generator\n",
        "#     self.criterion = criterion\n",
        "#     self.opt = opt\n",
        "\n",
        "#   def __call__(self, x, y, norm):\n",
        "#     x = self.generator(x)\n",
        "#     loss = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1))\n",
        "#     loss = loss / norm\n",
        "\n",
        "#     if self.opt is not None:  # training mode\n",
        "#       loss.backward()          \n",
        "#       self.opt.step()\n",
        "#       self.opt.zero_grad()\n",
        "\n",
        "#     return loss.data.item() * norm\n",
        "\n",
        "\n",
        "def run_epoch(data_loader, model, loss_compute, print_every):\n",
        "  \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "  total_tokens = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n",
        "    # We define some notations here to help you understand the loaded tensor\n",
        "    # shapes:\n",
        "    #   `B`: batch size\n",
        "    #   `T`: max sequence length of source sentences\n",
        "    #   `L`: max sequence length of target sentences; due to our preprocessing\n",
        "    #        in the beginning, `L` == `T` == 50\n",
        "    # An example of `src_ids_BxT` (when B = 2):\n",
        "    #   [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n",
        "    #    [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n",
        "    # The corresponding `src_lengths_B` would be [47, 49].\n",
        "    # Note that SOS_INDEX == 2, EOS_INDEX == 3, and PAD_INDEX = 0.\n",
        "\n",
        "    src_ids_BxT = src_ids_BxT.to(device)\n",
        "    src_lengths_B = src_lengths_B.to(device)\n",
        "    trg_ids_BxL = trg_ids_BxL.to(device)\n",
        "    del trg_lengths_B   # unused\n",
        "\n",
        "    _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
        "\n",
        "    loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:], norm=src_ids_BxT.size(0))\n",
        "    total_loss += loss\n",
        "    total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
        "\n",
        "    if model.training and i % print_every == 0:\n",
        "      print(\"Epoch Step: %d Loss: %f\" % (i, loss / src_ids_BxT.size(0)))\n",
        "\n",
        "  return math.exp(total_loss / float(total_tokens))\n",
        "\n",
        "\n",
        "def train(model, num_epochs, learning_rate, print_every):\n",
        "  # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when computing the loss.\n",
        "  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "  optim = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "  # Keep track of dev ppl for each epoch.\n",
        "  dev_ppls = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"epoch\", epoch)\n",
        "\n",
        "    model.train()\n",
        "    train_ppl = run_epoch(data_loader = train_data_loader, model = model,\n",
        "                          loss_compute = util.SimpleLossCompute(model.generator, criterion, optim),\n",
        "                          print_every = print_every)\n",
        "        \n",
        "    model.eval()\n",
        "    with torch.no_grad():      \n",
        "      dev_ppl = run_epoch(data_loader = val_data_loader, model = model,\n",
        "                          loss_compute = util.SimpleLossCompute(model.generator, criterion, None),\n",
        "                          print_every = print_every)\n",
        "      \n",
        "      print(\"Validation perplexity: %f\" % dev_ppl)\n",
        "      dev_ppls.append(dev_ppl)\n",
        "        \n",
        "  return dev_ppls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A8VvkcICT60",
        "colab_type": "text"
      },
      "source": [
        "3. The main function to perform training. First let's train the vanilla seq2seq model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ0t1hXAIHtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters for contructing the encoder-decoder model.\n",
        "\n",
        "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
        "hidden_size = 256  # RNN hidden size.\n",
        "dropout = 0.00\n",
        "\n",
        "pure_seq2seq = EncoderDecoder(\n",
        "  encoder = Encoder(embed_size, hidden_size, dropout = dropout),\n",
        "  decoder = Decoder(embed_size, hidden_size, dropout = dropout),\n",
        "  src_embed = nn.Embedding(len(src_vocab_set), embed_size),\n",
        "  trg_embed = nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "  generator = Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "# Start training. The returned `dev_ppls` is a list of dev perplexity for each epoch.\n",
        "pure_dev_ppls = train(pure_seq2seq, num_epochs = 10, learning_rate = 1e-3, print_every = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRsfDg0wCa7U",
        "colab_type": "text"
      },
      "source": [
        "4. Plot the perplexity graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTApnlT53YvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_perplexity(perplexities):\n",
        "  \"\"\"plot perplexities\"\"\"\n",
        "  plt.title(\"Perplexity per Epoch\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Perplexity\")\n",
        "  plt.plot(perplexities)\n",
        "\n",
        "plot_perplexity(pure_dev_ppls)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMpL-_MwJOws",
        "colab_type": "text"
      },
      "source": [
        "4. This is the function used to decode the model output. For simplicity, we use greedy search here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1HTqYwy6-yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: you might have to modify this `greedy_decode` function to work with your\n",
        "# `EncoderAttentionDecoder`.\n",
        "\n",
        "def greedy_decode(model, src_ids, src_lengths, max_len):\n",
        "  \"\"\"Greedily decode a sentence for EncoderDecoder.\"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "\n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "      hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n",
        "      prob = model.generator(outputs[:, -1])\n",
        "\n",
        "    _, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "\n",
        "  # Cut off everything starting from </s>.\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "  return output\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab):\n",
        "  return [vocab[i] for i in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_5go3VxJZKh",
        "colab_type": "text"
      },
      "source": [
        "5. Print the top 3 examples from the data loader by applying the greedy decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3m4optFrb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_examples(model, data_loader, n=3,\n",
        "                   max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS, \n",
        "                   src_vocab_set=src_vocab_set, trg_vocab_set=trg_vocab_set):\n",
        "  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
        "    result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                           max_len=max_len)\n",
        "\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    print(\"Example #%d\" % (i + 1))\n",
        "    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
        "    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
        "    print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab_set)))\n",
        "    print()\n",
        "\n",
        "    if i == n - 1:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Hi4X0GJouK",
        "colab_type": "text"
      },
      "source": [
        "6. Here we use the validation dataset to print examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27thJIfreCgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                        val_trg_sentences_list, trg_vocab_set)\n",
        "example_data_loader = data.DataLoader(val_set, batch_size=1, num_workers=1,\n",
        "                                      shuffle=False)\n",
        "\n",
        "print_examples(pure_seq2seq, example_data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5pTV5PqJtX4",
        "colab_type": "text"
      },
      "source": [
        "7. Compute the [BLEU](https://en.wikipedia.org/wiki/BLEU) score, a standard measure to evaluate the translation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XGQYwHRPyne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sacrebleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def compute_BLEU(model, data_loader):\n",
        "  bleu_score = []\n",
        "\n",
        "  model.eval()\n",
        "  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n",
        "    result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                           max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    pred = \" \".join(lookup_words(result, vocab=trg_vocab_set))\n",
        "    targ = \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set))\n",
        "\n",
        "    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n",
        "\n",
        "  return bleu_score\n",
        "\n",
        "\n",
        "test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n",
        "                     test_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n",
        "                                   shuffle=False)\n",
        "\n",
        "print('BLEU score: %f' % (np.mean(compute_BLEU(pure_seq2seq,\n",
        "                                               test_data_loader))))\n",
        "print('BLEU score: %f' % (np.mean(compute_BLEU(attn_seq2seq,\n",
        "                                               test_data_loader))))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}