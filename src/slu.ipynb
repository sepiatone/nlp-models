{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "slu.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E3UxdVAWh2m9",
        "aTmCgu06hXTT",
        "-j_0UKnEHN4R",
        "u0VYVg6RHN4o",
        "U4ODDfXKHN4s"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY7OK7jKHN4C",
        "colab_type": "text"
      },
      "source": [
        "# **Spoken Language Understanding** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfb2cp5fbhdT",
        "colab_type": "text"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "Spoken Language Understanding (SLU) is a field in NLP that involves elements from speech processing. The field of SLU is targeted at understanding human speech directed at machines (think [Mycroft](https://mycroft.ai/), Siri, Alexa and other voice assistants).\n",
        "\n",
        "SLU systems typically first parse utterences (or queries) into semantic frames comprised of intents and slots. The intent of a query could be something like \"get_direction\" for example and the slot could be \"cambridge\". Architectures have been proposed for filling in intents and slots separately and jointly.(See the references in this [paper](https://www.isca-speech.org/archive/Interspeech_2016/pdfs/1352.PDF) for an overview)\n",
        "\n",
        "The dataset consists of 44K annotated queries from this [paper](https://arxiv.org/pdf/1810.07942.pdf).\n",
        "\n",
        "The goal of this task it to semantically parse the user's query to obtain a tree structure with intents and slots as the nodes. For example the query \"what's there to do this weekend\" should be parsed to [IN:GET_EVENT whats there to do [SL:DATE_TIME this weekend ] ]. Note that the brackets [some span of text] indicate this span is a sub-tree. \n",
        " \n",
        "In Part B, we will implement a CKY decoding algorithm to decode the final tree based on the classifier we trained in Part A.\n",
        "\n",
        "Note: The Jupyter notebook framework was created by the excellent TA's for MIT 6.864 Advanced Natural Language Processing, Fall 2020. Pre-processing had been done to enable CKY-style decoding (code [here](https://github.mit.edu/tianxing/mit_6864_hw3_202003)) and the data are all binary trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3UxdVAWh2m9",
        "colab_type": "text"
      },
      "source": [
        "## **Part A**\n",
        "\n",
        "We formulate the problem as a simple classification problem, the input to the classifier will be (text, span) and the output will be the label of that span.\n",
        "\n",
        "We apply a model that learns the parsing structures in 4 steps.\n",
        "\n",
        "1. Enumerate all possible spans of a sentence\n",
        "2. Generating word and span embeddings\n",
        "3. Learning span classifications\n",
        "4. Decoding a tree structure using the classification distributions of spans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTmCgu06hXTT",
        "colab_type": "text"
      },
      "source": [
        "### **Setup**\n",
        "\n",
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIOkqXIoHN4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from span_tree import *\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\"   # use gpu!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQzMXTeHN4M",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Data Processing**\n",
        "\n",
        "Load the dataset or corpus, building the dictionary, the label dictionary and the span list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAauBjH1d9Up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "a61b6013-b2a3-4577-cba5-c44878dae282"
      },
      "source": [
        "def tree_dfs(node, span_list, label_dict, mode):\n",
        "  '''\n",
        "  We enumerate every node of a tree with depth first search (DFS).\n",
        "  '''\n",
        "\n",
        "  # print(node)\n",
        "  if len(node.children) == 0:\n",
        "      # print(type(node))\n",
        "      assert(type(node) == Token)\n",
        "      cur_span = (node.index, node.index + 1)\n",
        "      cur_label = label_dict['Token']\n",
        "      span_list.append([cur_span, cur_label])\n",
        "      return span_list, label_dict\n",
        "      \n",
        "  cur_span = node.get_token_span()\n",
        "  cur_label = node.label\n",
        "  \n",
        "  if node.label in label_dict:\n",
        "      cur_label = label_dict[node.label]\n",
        "  elif mode == 'train':\n",
        "      cur_label = len(label_dict)\n",
        "      label_dict[node.label] = cur_label\n",
        "  else:\n",
        "      cur_label = label_dict['UNK']\n",
        "  \n",
        "  span_list.append([cur_span, cur_label])\n",
        "  \n",
        "  if len(node.children) > 1: #if only has one child, we will ignore the Token label, otherwise the token span would have two conflicting labels\n",
        "      for child in node.children:\n",
        "          span_list, label_dict = tree_dfs(child, span_list, label_dict, mode)\n",
        "  \n",
        "  return span_list, label_dict\n",
        "\n",
        "  \n",
        "def process_line(line, vocab_dict, label_dict, mode):\n",
        "  '''\n",
        "  Processing a line in the corpus.\n",
        "  line format: Sentence \\t Sentence_Tree \\n\n",
        "  \n",
        "  Example:\n",
        "      'what is the shortest way home\\t\n",
        "      [IN:GET_DIRECTIONS what [SUB is [SUB the [SUB shortest [SUB way [SL:DESTINATION home ] ] ] ] ] ]\\n'\n",
        "  \n",
        "  Inputs:\n",
        "  vocab_dict: vocab dictionary {word: word_index, ...}\n",
        "  labels_dict: label dictionary {label: label_index, ...}\n",
        "  '''\n",
        "  s, s_tree = line.strip().split('\\t')\n",
        "  words = s.split(' ')\n",
        "  word_ids = []\n",
        "  \n",
        "  for word in words:\n",
        "      if word in vocab_dict:\n",
        "          word_ids.append(vocab_dict[word])\n",
        "      elif mode == 'train':\n",
        "          word_ids.append(len(vocab_dict))\n",
        "          vocab_dict[word] = len(vocab_dict)\n",
        "      else:\n",
        "          word_ids.append(vocab_dict['UNK'])\n",
        "  \n",
        "  tree = Tree(s_tree)\n",
        "  span_list = []\n",
        "  span_list, label_dict = tree_dfs(tree.root.children[0], span_list, label_dict, mode)\n",
        "  \n",
        "  return word_ids, span_list, vocab_dict, label_dict\n",
        "\n",
        "\n",
        "def process_corpus(corpus_path, mode, vocab_dict=None, label_dict=None):\n",
        "  '''\n",
        "  Note that we just adding new words and labels to the dictionaries while building the training set. Unseen words or labels in valid and test set are marked as unknown (UNK).\n",
        "  '''\n",
        "  \n",
        "  lines = open(corpus_path).readlines()\n",
        "    \n",
        "  if not vocab_dict:\n",
        "      vocab_dict = {'UNK': 0}\n",
        "  if not label_dict:\n",
        "      label_dict = {'UNK': 0, 'Token': 1, 'None': 2}\n",
        "  \n",
        "  corpus = []\n",
        "  sent_spans = []\n",
        "  \n",
        "  for line in lines:\n",
        "      word_ids, span_list, vocab_dict, label_dict = process_line(line, vocab_dict, label_dict, mode)\n",
        "      corpus.append(word_ids)\n",
        "      sent_spans.append(span_list)\n",
        "  \n",
        "  return corpus, sent_spans, vocab_dict, label_dict\n",
        "\n",
        "\n",
        "# corpus_train, spans_train, vocab_dict, label_dict = process_corpus(\"../data/slu_train.txt\", \"train\") # process_corpus('/content/6864-hw3a/train.txt', 'train')\n",
        "# corpus_valid, spans_valid, _, _ = process_corpus(\"../data/slu_valid.txt\", \"eval\", vocab_dict = vocab_dict, label_dict = label_dict)\n",
        "# corpus_test,  spans_test, _, _  = process_corpus(\"../data/slu_test.txt\", \"eval\", vocab_dict = vocab_dict, label_dict = label_dict)\n",
        "corpus_train, spans_train, vocab_dict, label_dict = process_corpus(\"../data/slu_train_1.txt\", \"train\") # process_corpus('/content/6864-hw3a/train.txt', 'train')\n",
        "\n",
        "num_words = len(vocab_dict)\n",
        "num_labels = len(label_dict)\n",
        "\n",
        "print('Number of different words: {}'.format(num_words))\n",
        "print('Number of different labels: {}'.format(num_labels))\n",
        "\n",
        "print(vocab_dict)\n",
        "print(label_dict)\n",
        "print()\n",
        "print(spans_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different words: 11\n",
            "Number of different labels: 8\n",
            "{'UNK': 0, 'how': 1, 'long': 2, 'will': 3, 'it': 4, 'take': 5, 'to': 6, 'drive': 7, 'from': 8, 'chicago': 9, 'mississippi': 10}\n",
            "{'UNK': 0, 'Token': 1, 'None': 2, 'IN:GET_ESTIMATED_DURATION': 3, 'SUB': 4, 'SL:METHOD_TRAVEL': 5, 'SL:SOURCE': 6, 'SL:DESTINATION': 7}\n",
            "\n",
            "[[[(0, 11), 3], [(0, 1), 1], [(1, 11), 4], [(1, 2), 1], [(2, 11), 4], [(2, 3), 1], [(3, 11), 4], [(3, 4), 1], [(4, 11), 4], [(4, 5), 1], [(5, 11), 4], [(5, 6), 1], [(6, 11), 4], [(6, 7), 5], [(7, 11), 4], [(7, 8), 1], [(8, 11), 4], [(8, 9), 6], [(9, 11), 4], [(9, 10), 1], [(10, 11), 7]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j_0UKnEHN4R",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Neural Networks\n",
        "\n",
        "### Sentence Encoding\n",
        "\n",
        "We use a Bi-directional LSTM for sentence encoding. We build a sentence encoder with a embedding layer and a Bi-directional LSTM layer.\n",
        "\n",
        "- Input: word indices [batch_size, sentence_length]\n",
        "- Output: word embeddings [batch_size, sentence_length, hidden_size]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTq0SpbfHN4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentEnc(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_words, num_layers, hidden_size, dropout=0):\n",
        "        super(SentEnc, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_words, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first = True, dropout = dropout, bidirectional = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # --------- Your code --------- #\n",
        "        \n",
        "        # --------- Your code ends --------- #\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em12BpkGHN4X",
        "colab_type": "text"
      },
      "source": [
        "### Span Encoding\n",
        "\n",
        "Given the LSTM outputs, we generate the span embeddings with the span indices.\n",
        "\n",
        "- Input: word embeddings [sentence_length, hidden_size], span indices [num_span, 2]\n",
        "- Output: span embeddings [num_span, hidden_size]\n",
        "\n",
        "We generate a span embedding by concatenate the word embeddings of the first and last words of a span. For example, if a span starts from the i-th word and ends at the j-th word, our span embedding would be\n",
        "\n",
        "[h_i^T; h_j^T]^T,\n",
        "\n",
        "where h_i stands for the Bi-LSTM output of the i-th word.\n",
        "\n",
        "In pytorch, Given the hidden states h[0], h[1], ..., h[n], where\n",
        "```\n",
        "h[i].size() = [1, k]\n",
        "```\n",
        "the embedding of span (i, j) is\n",
        "```\n",
        "span_ij = torch.cat([h[i], h[j]], dim=1)\n",
        "span_ij.size() = [1, 2 * k]\n",
        "```\n",
        "Please complete the following function for generating span embeddings.\n",
        "\n",
        "Inputs:\n",
        "- word_embeddings (LSTM outputs) [n_words, hidden_size]\n",
        "- Span indices [n_spans, 2]\n",
        "\n",
        "Outputs:\n",
        "- span embeddings [n_spans, hidden_size * 2]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afGE-9pZHN4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_span_embeddings(word_embeddings, span_indices):\n",
        "    # --------- Your code --------- #\n",
        "    \n",
        "    # --------- Your code ends --------- #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmDK0xKfHN4g",
        "colab_type": "text"
      },
      "source": [
        "### Tag Prediction\n",
        "\n",
        "We build a Classifier that puts the neural models together. The classifier takes word and span indices as inputs, and predict span labels by calculating word embeddings, span embeddings, and label logits. we will predict the tag of the spans with a linear classifier.\n",
        "\n",
        "- Inputs: word indices: [batch_size, num_words]\n",
        "- Outputs: span predictions: [num_spans, num_labels]\n",
        "\n",
        "Please implement the forward function following the 3 steps:\n",
        "1. Generate the word embeddings by processing the input sentences with the LSTM sentence encoder.\n",
        "2. Apply dropout on word embeddings.\n",
        "3. Calculate span embeddings with function get_span_embeddings().\n",
        "4. Calculate label logits with the linear layer defined as follow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtWAptvBHN4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_words, num_labels, num_layers, hidden_size, dropout=0):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.sent_enc = SentEnc(num_words, num_layers, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(4 * hidden_size, num_labels)\n",
        "    \n",
        "    def forward(self, x, span_indices):\n",
        "        # --------- Your code --------- #\n",
        "        \n",
        "        # --------- Your code ends --------- #\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VYVg6RHN4o",
        "colab_type": "text"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "With all neural models already defined, we are implementing the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B82dn5UhHN4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For decoding, we add some random spans and label them as \"None\"\n",
        "def add_none_span(word_list, span_list, label_dict, all=False):\n",
        "    num_words = len(word_list)\n",
        "    num_labeled_span = len(span_list)\n",
        "    labeled_span_set = set([span for span, label in span_list])\n",
        "    none_spans = []\n",
        "    for i in range(num_words):\n",
        "        for j in range(i + 1, num_words):\n",
        "            if (i, j) not in labeled_span_set:\n",
        "                none_spans.append([(i, j), label_dict['None']])\n",
        "    if not all:\n",
        "        k = min(num_labeled_span, len(none_spans))\n",
        "        sampled_none_spans = random.sample(none_spans, k)\n",
        "    else:\n",
        "        sampled_none_spans = none_spans\n",
        "    return span_list + sampled_none_spans\n",
        "\n",
        "print('Using device: {}'.format(device))\n",
        "\n",
        "# --------- Your code --------- #\n",
        "# There's no code here, just remeber you can tune these hyper-parameters!\n",
        "# --------- Your code ends --------- #\n",
        "batch_size = 1\n",
        "num_layers = 2\n",
        "hidden_size = 200\n",
        "lr = 0.05\n",
        "num_epochs = 3 #Be aware of over-fitting!\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "dropout = 0.25\n",
        "\n",
        "classifier = Classifier(num_words, num_labels, num_layers, hidden_size, dropout)\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "classifier = classifier.to(device)\n",
        "classifier.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    classifier.train()\n",
        "    for i in range(len(corpus_train)):\n",
        "\n",
        "        if i % 10000 == 0:\n",
        "            print('Epoch {} Batch {}'.format(epoch, i))\n",
        "        \n",
        "        cur_spans = add_none_span(corpus_train[i], spans_train[i], label_dict)\n",
        "        \n",
        "        sent_inputs  = torch.Tensor([corpus_train[i]]).long().to(device)\n",
        "        span_indices = torch.Tensor([x[0] for x in cur_spans]).long().to(device)\n",
        "        span_labels  = torch.Tensor([x[1] for x in cur_spans]).long().to(device)\n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "\n",
        "        # --------- Your code ends --------- #\n",
        "    print('Epoch {}, train loss={}'.format(epoch, total_loss / len(corpus_train)))\n",
        "\n",
        "    total_loss = 0\n",
        "    classifier.eval()\n",
        "    for i in range(len(corpus_valid)):\n",
        "        #if i % 10000 == 0:\n",
        "        #    print('Epoch {} Batch {}'.format(epoch, i))\n",
        "        cur_spans = add_none_span(corpus_valid[i], spans_valid[i], label_dict)\n",
        "        \n",
        "        sent_inputs  = torch.Tensor([corpus_valid[i]]).long().to(device)\n",
        "        span_indices = torch.Tensor([x[0] for x in cur_spans]).long().to(device)\n",
        "        span_labels  = torch.Tensor([x[1] for x in cur_spans]).long().to(device)\n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "\n",
        "        # --------- Your code ends --------- #\n",
        "    print('Epoch {}, valid loss={}'.format(epoch, total_loss / len(corpus_valid)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ODDfXKHN4s",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "After training the model, we evaluate the classification result.  \n",
        "What we will do is that we treat a tree strcture as a bag of spans, and then compute F-1 score.  \n",
        "You don't need to write any code in this section. But it's good for you to understand what it's doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH5bRW6UHN4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import zip_longest\n",
        "from typing import Counter, Dict, Optional\n",
        "import numpy as np\n",
        "\n",
        "class Calculator:\n",
        "    def __init__(self, strict: bool = False) -> None:\n",
        "        self.num_gold_nt: int = 0\n",
        "        self.num_pred_nt: int = 0\n",
        "        self.num_matching_nt: int = 0\n",
        "        self.strict: bool = strict\n",
        "        self.exact_match = []\n",
        "        self.well_form = []\n",
        "\n",
        "    def get_metrics(self):\n",
        "        precision: float = (\n",
        "            self.num_matching_nt / self.num_pred_nt) if self.num_pred_nt else 0\n",
        "        recall: float = (\n",
        "            self.num_matching_nt / self.num_gold_nt) if self.num_gold_nt else 0\n",
        "        f1: float = (2.0 * precision * recall /\n",
        "                     (precision + recall)) if precision + recall else 0\n",
        "        \n",
        "        return {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1,\n",
        "            \"exact_match\": np.mean(self.exact_match),\n",
        "            \"well_form\": np.mean(self.well_form),\n",
        "        }\n",
        "    \n",
        "    def add_instance_span(self, gold_spans, pred_spans):\n",
        "        self.num_gold_nt += len(gold_spans)\n",
        "        self.num_pred_nt += len(pred_spans)\n",
        "        gold_spans = set(gold_spans)\n",
        "        pred_spans = set(pred_spans)\n",
        "        self.num_matching_nt += len(gold_spans & pred_spans)\n",
        "        self.exact_match.append(int(gold_spans == pred_spans))\n",
        "        well_form = True\n",
        "        for s1 in pred_spans: \n",
        "            for s2 in pred_spans:\n",
        "                if s1[0] < s2[0] and s2[0] < s1[1] and s1[1] < s2[1]:\n",
        "                    well_form = False\n",
        "        self.well_form.append(int(well_form))\n",
        "\n",
        "    def add_instance_tree(self, gold_tree: Tree,\n",
        "                     pred_tree: Optional[Tree] = None) -> None:\n",
        "        node_info_gold: Counter = self._get_node_info(gold_tree)\n",
        "        self.num_gold_nt += sum(node_info_gold.values())\n",
        "            \n",
        "        if pred_tree:\n",
        "            node_info_pred: Counter = self._get_node_info(pred_tree)\n",
        "            self.num_pred_nt += sum(node_info_pred.values())\n",
        "            self.num_matching_nt += sum(\n",
        "                (node_info_gold & node_info_pred).values())\n",
        "            self.exact_match.append(int(node_info_gold.keys() == node_info_pred.keys()))\n",
        "            self.well_form.append(1) #we assume the decoded tree is indeed a tree :)\n",
        "        \n",
        "    def _get_node_info(self, tree) -> Counter:\n",
        "        nodes = tree.root.list_nonterminals()\n",
        "        node_info: Counter = Counter()\n",
        "        for node in nodes:\n",
        "            #node_info[(node.label, self._get_span(node))] += 1 #here I change it to only care about the span\n",
        "            node_info[(self._get_span(node))] += 1\n",
        "        return node_info\n",
        "\n",
        "    def _get_span(self, node):\n",
        "        return node.get_flat_str_spans(\n",
        "        ) if self.strict else node.get_token_span()\n",
        "\n",
        "\n",
        "classifier.eval()\n",
        "num_correct = 0.\n",
        "num_spans = 0\n",
        "calc = Calculator(strict=False)\n",
        "\n",
        "for kk in range(len(corpus_test)):\n",
        "    #we will create bag of spans based on our prediction\n",
        "\n",
        "    #cur_spans = add_none_span(corpus_test[i], spans_test[i], label_dict)\n",
        "    cur_spans = spans_test[kk]\n",
        "    cur_spans = [x for x in cur_spans if x[0][1] > x[0][0] + 1] #only test non-terminals\n",
        "    #print(cur_spans)\n",
        "    if len(cur_spans) <= 1: continue\n",
        "    gold_spans = [x[0] for x in cur_spans]\n",
        "\n",
        "    tokens = corpus_test[kk]\n",
        "    cur_len = len(corpus_test[kk])\n",
        "    sent_inputs  = torch.Tensor([tokens]).long().to(device)\n",
        "    all_spans = []\n",
        "    for i in range(cur_len):\n",
        "        for j in range(i + 2, cur_len + 1):\n",
        "            all_spans.append((i,j))\n",
        "    logits = classifier(sent_inputs, torch.Tensor(all_spans).long().to(device))\n",
        "    #logprobs = torch.log(torch.softmax(logits, dim = -1))\n",
        "    \n",
        "    pred_spans = []\n",
        "    for i, span in enumerate(all_spans):\n",
        "        if torch.argmax(logits[i]).item() != 2:\n",
        "            pred_spans.append(span)\n",
        "    \n",
        "    calc.add_instance_span(gold_spans, pred_spans)\n",
        " \n",
        "print(calc.get_metrics())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasnfaK4qTfU",
        "colab_type": "text"
      },
      "source": [
        "## **Part B**  \n",
        "\n",
        "In part B, we will decode a tree based on the classifier trained on part A.  \n",
        "Important hint: You should avoid the \"None\" type during the decoding.  \n",
        "\n",
        "You will be implementing the following simple CYK recursion:  \n",
        "best_score[i, j] = max_k {best_score[i, k] + best_score[k, j]} + max_l {span_dict[(i, j)][l]}  \n",
        "where l is the label of the current span (i,j), and k is the splitting point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHPVa39Fqhhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dp_results = []\n",
        "classifier.eval()\n",
        "for kk, line in enumerate(open('/content/6864-hw3a/test.txt', 'r').readlines()):\n",
        "    line = line.strip()\n",
        "    if len(line) < 3: continue\n",
        "    if kk < 10:\n",
        "        print(kk, line)\n",
        "    tokens = corpus_test[kk]\n",
        "    sent_inputs  = torch.Tensor([corpus_test[kk]]).long().to(device)\n",
        "    all_spans = []\n",
        "    for i in range(len(tokens)):\n",
        "        for j in range(i + 1, len(tokens) + 1):\n",
        "            all_spans.append((i,j))\n",
        "    logits = classifier(sent_inputs, torch.Tensor(all_spans).long().to(device))\n",
        "    logprobs = torch.log(torch.softmax(logits, dim = -1))\n",
        "    span_dict = {}\n",
        "    for i, s in enumerate(all_spans): span_dict[s] = logprobs[i] #span dict will map each span (l,r) to its predicted distribution of labels\n",
        "    TOKEN_ID, NULL_ID = 1, 2\n",
        "    best_score, best_split, best_label = {}, {}, {} #we will do dynamic programming to decode a binary tree out of our predictions\n",
        "    \n",
        "    #Think: why do we first iterate the length of the span?\n",
        "    for ll in range(1, len(tokens) + 1): #length of the span\n",
        "        for i in range(0, len(tokens)): #start of the span\n",
        "            if i + ll > len(tokens): break\n",
        "            j = i + ll; cur_span = (i, j)\n",
        "            if j == i + 1:\n",
        "                # --------- Your code --------- #\n",
        "                #use span_dict[cur_span] to update best_label and best_score, be careful, it could either be a TOKEN or something else\n",
        "\n",
        "                # --------- Your code ends --------- #\n",
        "            else:\n",
        "                span_dict[cur_span][NULL_ID] = -100000 #we will never decode a NULL sub-tree\n",
        "                span_dict[cur_span][TOKEN_ID] = -100000 #we will never decode a NULL sub-tree\n",
        "                # --------- Your code --------- #\n",
        "                #try to give the values for best_score/label/split[cur_span]\n",
        "\n",
        "                # --------- Your code ends --------- #\n",
        "            #print(cur_span, best_score[cur_span], best_label[cur_span])\n",
        "    dp_results.append((best_score, best_split, best_label))\n",
        "print(len(dp_results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp7gnX87QFog",
        "colab_type": "text"
      },
      "source": [
        "In the next section, we will construct a tree using the dp results.  \n",
        "Before start doing it, please get yourself a little familiar with the span_tree.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpKRpZEiSNF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inv_label_dict = {}\n",
        "for l in label_dict: inv_label_dict[label_dict[l]] = l\n",
        "#print(inv_label_dict)\n",
        "\n",
        "def get_nodetype(label):\n",
        "    if label.startswith(PREFIX_INTENT):\n",
        "        node = Intent(label)\n",
        "    elif label.startswith(PREFIX_SLOT):\n",
        "        node = Slot(label)\n",
        "    elif label.startswith(PREFIX_SUBTREE):\n",
        "        node = SubTree(label)\n",
        "    else:\n",
        "        print('something wrong with the label!!!', label, l, r)\n",
        "        sys.exit(1)\n",
        "    return node\n",
        "\n",
        "def dfs_build(l, r):\n",
        "\n",
        "    if l + 1 == r:\n",
        "        la = best_label[(l,r)]\n",
        "        if la == 1:\n",
        "            return Token(surface_tokens[l], l)\n",
        "        else:\n",
        "            node = get_nodetype(inv_label_dict[la])\n",
        "            node.children = [Token(surface_tokens[l], l)]\n",
        "            node.children[0].parent = node\n",
        "            return node\n",
        "\n",
        "    label = inv_label_dict[best_label[(l, r)]]\n",
        "    node = get_nodetype(label)\n",
        "    \n",
        "    #--- your code --- #\n",
        "    #hint: only need one line, use best_split!\n",
        "\n",
        "    #--- your code ends --- #\n",
        "\n",
        "    for c in node.children:\n",
        "        c.parent = node\n",
        "    \n",
        "    return node\n",
        "\n",
        "pred_trees = []\n",
        "for kk, line in enumerate(open('/content/6864-hw3a/test.txt', 'r').readlines()):\n",
        "    tt = line.strip().split('\\t')\n",
        "    surface_tokens, str_ref_tree = tt[0].split(), tt[1]\n",
        "    if len(line) < 3: continue\n",
        "    tokens = corpus_test[kk]\n",
        "    cur_len = len(tokens)\n",
        "    best_score, best_split, best_label = dp_results[kk]\n",
        "    #print(inv_label_dict[best_label[(0, cur_len)]], best_split[(0, cur_len)])\n",
        "    root = Root()\n",
        "    root.children = [dfs_build(0, cur_len)]\n",
        "    root.children[0].parent = root\n",
        "    tree = Tree('IN:GET_EVENT placeholder') #the string here is just a placeholder\n",
        "    tree.root = root\n",
        "    if kk < 10: #use this info for debugging! Does your tree make sense?\n",
        "        print(kk, line.strip())\n",
        "        print('REF:', str_ref_tree)\n",
        "        print('DEC:', str(tree))\n",
        "        print()\n",
        "    \"\"\" here's some decoding examples we get\n",
        "    0 whats there to do this weekend\t[IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "    REF: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "    DEC: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "\n",
        "    1 what is a good restaurant for tex mex in austin\t[IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "    REF: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "    DEC: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "    2 where can i see the fireworks tonight\t[IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
        "    REF: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
        "    DEC: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB the [SUB fireworks [SL:DATE_TIME tonight ] ] ] ] ] ] ]\n",
        "    \"\"\"\n",
        "    pred_trees.append(tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJXGohgsWZCs",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will compute the F1 score, using the pred_trees.  \n",
        "You don't need to write any code in this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRInPh7IWgbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(pred_trees))\n",
        "#compute the score!\n",
        "labeled_bracketing_scores = Calculator(strict=False)\n",
        "\n",
        "for kk, line in enumerate(open('/content/6864-hw3a/test.txt', 'r').readlines()):\n",
        "    tt = line.strip().split('\\t')\n",
        "    surface_tokens, str_ref_tree = tt[0].split(), tt[1]\n",
        "    if len(line) < 3: continue\n",
        "    tokens = corpus_test[kk]\n",
        "    labeled_bracketing_scores.add_instance_tree(Tree(str_ref_tree), pred_trees[kk])\n",
        "\n",
        "print(labeled_bracketing_scores.get_metrics())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvT7-lGzbT2W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}